#!/usr/bin/env python
import contextlib as __stickytape_contextlib

@__stickytape_contextlib.contextmanager
def __stickytape_temporary_dir():
    import tempfile
    import shutil
    dir_path = tempfile.mkdtemp()
    try:
        yield dir_path
    finally:
        shutil.rmtree(dir_path)

with __stickytape_temporary_dir() as __stickytape_working_dir:
    def __stickytape_write_module(path, contents):
        import os, os.path

        def make_package(path):
            parts = path.split("/")
            partial_path = __stickytape_working_dir
            for part in parts:
                partial_path = os.path.join(partial_path, part)
                if not os.path.exists(partial_path):
                    os.mkdir(partial_path)
                    with open(os.path.join(partial_path, "__init__.py"), "wb") as f:
                        f.write(b"\n")

        make_package(os.path.dirname(path))

        full_path = os.path.join(__stickytape_working_dir, path)
        with open(full_path, "wb") as module_file:
            module_file.write(contents)

    import sys as __stickytape_sys
    __stickytape_sys.path.insert(0, __stickytape_working_dir)

    __stickytape_write_module('range_analysis_app/__init__.py', b'')
    __stickytape_write_module('range_analysis_app/components/__init__.py', b'')
    __stickytape_write_module('range_analysis_app/components/streamlit_nested_layout.py', b'# Implementation from streamlit-nested-layout => https://github.com/joy13975/streamlit-nested-layout\n# This package is not available in the Snowflake Anaconda Channel => https://repo.anaconda.com/pkgs/snowflake/\n\nfrom streamlit.delta_generator import *\nfrom streamlit.delta_generator import _enqueue_message\n\n\ndef _nestable_block(\n    self: "DeltaGenerator",\n    block_proto: Block_pb2.Block = Block_pb2.Block(),\n) -> "DeltaGenerator":\n    # Operate on the active DeltaGenerator, in case we\'re in a `with` block.\n    dg = self._active_dg\n\n    # Prevent nested columns & expanders by checking all parents.\n    block_type = block_proto.WhichOneof("type")\n    # Convert the generator to a list, so we can use it multiple times.\n    # parent_block_types = frozenset(dg._parent_block_types)\n    # if block_type == "column" and block_type in parent_block_types:\n    #     raise StreamlitAPIException(\n    #         "Columns may not be nested inside other columns."\n    #     )\n    # if block_type == "expandable" and block_type in parent_block_types:\n    #     raise StreamlitAPIException(\n    #         "Expanders may not be nested inside other expanders."\n    #     )\n\n    if dg._root_container is None or dg._cursor is None:\n        return dg\n\n    msg = ForwardMsg_pb2.ForwardMsg()\n    msg.metadata.delta_path[:] = dg._cursor.delta_path\n    msg.delta.add_block.CopyFrom(block_proto)\n\n    # Normally we\'d return a new DeltaGenerator that uses the locked cursor\n    # below. But in this case we want to return a DeltaGenerator that uses\n    # a brand new cursor for this new block we\'re creating.\n    block_cursor = cursor.RunningCursor(\n        root_container=dg._root_container,\n        parent_path=dg._cursor.parent_path + (dg._cursor.index,),\n    )\n    block_dg = DeltaGenerator(\n        root_container=dg._root_container,\n        cursor=block_cursor,\n        parent=dg,\n        block_type=block_type,\n    )\n    # Blocks inherit their parent form ids.\n    # NOTE: Container form ids aren\'t set in proto.\n    block_dg._form_data = FormData(current_form_id(dg))\n\n    # Must be called to increment this cursor\'s index.\n    dg._cursor.get_locked_cursor(last_index=None)\n    _enqueue_message(msg)\n\n    caching.save_block_message(\n        block_proto,\n        invoked_dg_id=self.id,\n        used_dg_id=dg.id,\n        returned_dg_id=block_dg.id,\n    )\n\n    return block_dg\n\n\nDeltaGenerator._block = _nestable_block\n')
    __stickytape_write_module('app_pages/__init__.py', b'')
    __stickytape_write_module('app_pages/about_page.py', b'import streamlit as st\n\nfrom app_pages.page import Page\n\n\nclass AboutPage(Page):\n    @property\n    def page_description(self) -> str:\n        return "About Maxa"\n\n    def run(self) -> None:\n        st.markdown(\n            """\n            Maxa is a cutting-edge financial data platform powered by Snowflake that allows you to: \n            - Transform and blend raw data from multiple systems\n            - Automate data extraction from ERP and core systems\n            - User-friendly data model for easy navigation\n            - Gain actionable insights and drive improvements\n\n            If you are interested to see how Maxa can transform your business, contact us:\n            - Email: [snowflake-info@maxa.ai](mailto:snowflake-info@maxa.ai)\n            - Website: [maxa.ai/contact](https://www.maxa.ai/contact/)\n            """\n        )\n')
    __stickytape_write_module('app_pages/page.py', b'import abc\n\n\nclass Page(abc.ABC):\n    @property\n    @abc.abstractmethod\n    def page_description(self) -> str:\n        pass\n\n    @abc.abstractmethod\n    def run(self) -> None:\n        pass\n')
    __stickytape_write_module('app_pages/dashboard.py', b'from typing import Literal, Optional, Type\n\nimport streamlit as st\nfrom pydantic import BaseModel\n\nfrom app_pages.page import Page\nfrom data.helpers import repository\nfrom range_analysis_app.exploration.plotly_styles import INDICATOR_SELECTED_STYLE, PLOTLY_CONFIG, SELECTED_STYLE\nfrom utils import groupby\nfrom widgets.widget import Widget\nfrom widgets.widget_gallery import widget_gallery\n\n\nclass DashboardState(BaseModel):\n    """State of the Dashboard:\n    - list-widgets: Show the list of current dashboard widgets in the sidebar\n    - add-widget: Show the gallery of available widgets in the sidebar\n    - edit-widget: Highlight a selected widget and edit its parameters in the sidebar\n    """\n\n    sidebar: Literal["list-widgets", "add-widget", "edit-widget"] = "list-widgets"\n    selected_widget: Optional[Widget]\n\n\nclass DashboardPage(Page):\n    def __init__(self) -> None:\n        if "dashboard_state" not in st.session_state:\n            st.session_state["dashboard_state"] = DashboardState()\n\n        self.state: DashboardState = st.session_state["dashboard_state"]\n\n    @property\n    def page_description(self) -> str:\n        return "Dashboard of saved visualizations."\n\n    def run(self) -> None:\n        if not repository().is_valid():\n            st.warning("Go to the **Configuration** tab to map your data.")\n            return\n\n        self.render_widgets()\n\n        with st.sidebar:\n            self.widget_list()\n\n            # if self.state.sidebar == "add-widget":\n\n            #     def add_and_edit_widget(widget_class: Type[Widget]):\n            #         repository().widgets.append(widget_class.default())\n\n            #     widget_gallery(on_add=add_and_edit_widget)\n            #     return\n\n            if self.state.sidebar == "edit-widget":\n                self.state.selected_widget.edit_parameters()\n                return\n\n    def render_widgets(self) -> None:\n        """Charts of all the dashboard widgets aligned in two columns."""\n        widgets = repository().widgets\n        kpi_widgets = [widget for widget in widgets if widget.widget_kind == "kpi"]\n        chart_widgets = groupby([widget for widget in widgets if widget.widget_kind == "chart"], key=lambda w: w.size)\n\n        # Top row: Text + 4 KPIs\n        text_col, *kpi_cols = st.columns([4] + [2] * 4)\n        text_col.markdown(\n            """\n            ### :blue[ERP Sales Assessment]\n            \n            Identify trends, anomalies and top product categories to drive cost savings and improve financial performance.\n            """\n        )\n        for col, kpi in zip(kpi_cols, kpi_widgets):\n            with col:\n                widget_kpi(kpi, is_selected=kpi is self.state.selected_widget)\n\n        # Middle row: 3 medium charts\n        cols = st.columns([4, 4, 4])\n        for widget, col in zip(chart_widgets["medium"], cols):\n            with col:\n                widget_chart(widget, is_selected=widget is self.state.selected_widget)\n\n        # Bottom row: 1 large chart + 1 text\n        left, right = st.columns([6, 6])\n        if chart_widgets["large"] and (widget := chart_widgets["large"].pop()):\n            with left:\n                widget_chart(widget, is_selected=widget is self.state.selected_widget)\n\n        with right:\n            with st.expander("**Purchasing Behavior and Anomalies**", expanded=True):\n                st.markdown(\n                    """\n                    \n                    - Gain valuable insights into purchasing behavior\n                    - Track revenue trends and compare years\n                    - Identify anomalies and outliers in purchasing patterns\n\n                    """\n                )\n\n            with st.expander("**Streamline Procurement**", expanded=True):\n                st.markdown(\n                    """\n                    - Simplify procurement analysis and boost financial performance\n                    - Visualize product distribution with pie charts\n                    - Equip financial managers with actionable insights\n                    """\n                )\n\n    def widget_list(self):\n        """List of widgets with action buttons: Edit, Remove."""\n\n        # def add_widget():\n        #     self.state.sidebar = "add-widget"\n\n        # st.button("\\+ Add widget", use_container_width=True, on_click=add_widget)\n\n        widgets = repository().widgets\n        kpi_widgets = [widget for widget in widgets if widget.widget_kind == "kpi"]\n        chart_widgets = [widget for widget in widgets if widget.widget_kind == "chart"]\n\n        with st.expander("**KPIs**"):\n            for index, widget in enumerate(kpi_widgets):\n                self.widget_list_item(index, widget)\n\n        with st.expander("**Charts**"):\n            for index, widget in enumerate(chart_widgets):\n                self.widget_list_item(index + len(kpi_widgets), widget)\n\n    def widget_list_item(self, index: int, widget: Widget) -> None:\n        is_selected = self.state.selected_widget is widget\n\n        def edit_or_unselect_widget():\n            if is_selected:\n                self.state.sidebar = "list-widgets"\n                self.state.selected_widget = None\n            else:\n                self.state.sidebar = "edit-widget"\n                self.state.selected_widget = widget\n\n        title = widget.displayed_title()\n\n        cols = st.columns([4, 1])\n        cols[0].markdown(f"**:blue[{title}]**" if is_selected else title)\n        cols[1].button(\n            "\xe2\x9c\x8e",\n            key=f"edit-{index}",\n            use_container_width=True,\n            on_click=edit_or_unselect_widget,\n            type="primary" if is_selected else "secondary",\n        )\n\n\ndef widget_chart(widget: Widget, is_selected: bool) -> None:\n    """Render the chart of the given widget."""\n    st.plotly_chart(\n        widget.figure().update_layout(SELECTED_STYLE if is_selected else {}),\n        config=PLOTLY_CONFIG,\n        use_container_width=True,\n    )\n\n\ndef widget_kpi(kpi: Widget, is_selected: bool) -> None:\n    """Render the indicator of the given KPI widget."""\n    st.plotly_chart(\n        kpi.figure().update_layout(INDICATOR_SELECTED_STYLE if is_selected else {}),\n        config=PLOTLY_CONFIG,\n        use_container_width=True,\n    )\n')
    __stickytape_write_module('data/__init__.py', b'')
    __stickytape_write_module('data/helpers.py', b'from datetime import datetime\nfrom typing import TYPE_CHECKING, Any, Callable, List, Set, Tuple\n\nimport pandas as pd\nimport streamlit as st\nfrom inflection import pluralize as inflection_pluralize\nfrom snowflake.snowpark.exceptions import SnowparkSQLException\nfrom snowflake.snowpark.types import StringType, StructField, StructType, TimestampType\n\nfrom range_analysis_app.db import snowflake_session\nfrom utils import pluralize\n\nif TYPE_CHECKING:\n    from data.models import DomaBaseModel\n    from data.repository import Repository\n\n\nDB_TABLE = "doma_entities"\nDB_TABLE_SCHEMA = StructType(\n    [\n        StructField("name", StringType()),\n        StructField("json_data", StringType()),\n        StructField("updated_at", TimestampType()),\n    ]\n)\n\n\ndef create_table_if_not_exists() -> None:\n    try:\n        snowflake_session().table(DB_TABLE).collect()\n    except SnowparkSQLException as e:\n        (\n            snowflake_session()\n            .create_dataframe([], schema=DB_TABLE_SCHEMA)\n            .write.save_as_table(DB_TABLE, mode="overwrite")\n        )\n\n\ndef load_and_select_repository() -> None:\n    default_mode = "Demo Mode"\n\n    if "repository" not in st.session_state:\n        from data.repository import Repository\n        from sample_configuration import sample_config\n\n        create_table_if_not_exists()\n        st.session_state.demo_repository = Repository.parse_obj(sample_config)\n\n        row = snowflake_session().table(DB_TABLE).first()\n\n        if row is None:\n            st.session_state.repository = Repository.default_for_purchase_orders()\n        else:\n            data = row.JSON_DATA\n            st.session_state["prev_repository_json"] = data\n            st.session_state.repository = Repository.parse_raw(data)\n            st.session_state.last_updated_at = row.UPDATED_AT\n\n            if st.session_state.repository.is_valid():\n                default_mode = "Custom Mode"\n\n    MODES = ["Demo Mode", "Custom Mode"]\n\n    st.sidebar.radio(\n        "**Data Source**",\n        MODES,\n        index=MODES.index(default_mode),\n        horizontal=True,\n        key="selected_repository",\n    )\n\n\ndef repository() -> "Repository":\n    """Return the currently selected repository."""\n    if st.session_state.get("selected_repository") == "Custom Mode":\n        return st.session_state.repository\n    else:\n        return st.session_state.demo_repository\n\n\ndef save_repo_button(\n    label: str,\n    key: str,\n    include: Set[str] = None,\n    exclude: Set[str] = None,\n    before_save: Callable[..., Any] = None,\n) -> bool:\n    """Component for saving the repository and going to the next page."""\n    from data.repository import Repository\n\n    raw_json = st.session_state.repository.json(include=include, exclude=exclude)\n\n    prev_raw_json = st.session_state.get("prev_repository_json")\n    if prev_raw_json:\n        prev_raw_json = Repository.parse_raw(prev_raw_json).json(include=include, exclude=exclude)\n\n    disabled = prev_raw_json == raw_json\n\n    placeholder = st.empty()\n\n    btn_container = placeholder.container()\n    btn_container.markdown("")\n\n    if btn_container.button(label, key=key, type="primary", use_container_width=True, disabled=disabled):\n        placeholder.empty()\n        if before_save:\n            before_save()\n\n        with st.spinner():\n            (\n                snowflake_session()\n                .create_dataframe(\n                    [["Custom config", st.session_state.repository.json(), datetime.now()]],\n                    schema=DB_TABLE_SCHEMA,\n                )\n                .write.save_as_table(DB_TABLE, mode="overwrite")\n            )\n\n        st.session_state["prev_repository_json"] = st.session_state.repository.json()\n        st.session_state.last_updated_at = datetime.now()\n        placeholder.info("Saved.", icon="\xe2\x9c\x94\xef\xb8\x8f")\n        return True\n\n    return False\n\n\ndef validate_state(\n    models: List["DomaBaseModel"],\n    entity_name: str,\n    permit_empty: bool = False,\n    validate_each: bool = True,\n) -> Tuple[bool, str]:\n    """Return a pair (is_valid, message) describing the validation state of the given models."""\n\n    if len(models) == 0 and not permit_empty:\n        return False, f"{entity_name} cannot be empty"\n\n    if validate_each:\n        try:\n            success_message = [f"{pluralize(len(models), entity_name)} has been set"]\n            for model in models:\n                model.validate_entity()\n                success_message.append(f"- {model.validation_item_name()}")\n\n            return True, "\\n".join(success_message)\n        except ValueError as e:\n            return False, str(e)\n\n    success_message = f"All set for the {inflection_pluralize(entity_name)}"\n    return True, "\\n".join([success_message] + [f"- {x.validation_item_name()}" for x in models])\n\n\ndef render_validation_component(is_valid: bool, message: str):\n    if is_valid:\n        st.success(message, icon="\xe2\x9c\x94\xef\xb8\x8f")\n    else:\n        st.error(message, icon="\xe2\x9c\x96\xef\xb8\x8f")\n')
    __stickytape_write_module('range_analysis_app/db.py', b'import json\nfrom typing import Dict, Iterable, List, Literal, TypedDict, Union, get_args\n\nimport pandas as pd\nimport snowflake.snowpark.functions as f\nimport streamlit as st\nfrom pydantic import Field\nfrom snowflake.snowpark import Session\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.exceptions import SnowparkSessionException\nfrom typing_extensions import NotRequired\n\nfrom utils import BaseModelCacheKey\n\n\n@st.cache_resource\ndef snowflake_session() -> Session:\n    try:\n        return get_active_session()\n    except SnowparkSessionException:\n        return Session.builder.configs(st.secrets["snowflake"]).create()\n\n\n@st.cache_data\ndef fetch_tables(schema: str = "") -> List[str]:\n    return [row.name for row in snowflake_session().sql(f"show tables in schema {schema}").collect()]\n\n\nDatetimeType = Literal["DATE", "TIME", "TIMESTAMP", "TIMESTAMP_LTZ", "TIMESTAMP_NTZ"]\nDataType = Union[Literal["TEXT", "FIXED", "REAL", "BINARY", "BOOLEAN", "ARRAY", "OBJECT"], DatetimeType]\nExtendedDataType = Union[DataType, Literal["INTEGER"]]\n\nDATETIME_TYPES: Iterable[DatetimeType] = get_args(DatetimeType)\nID_TYPES: Iterable[ExtendedDataType] = ["TEXT", "INTEGER", "BINARY", "ARRAY"]\n\n\n@st.cache_data\ndef fetch_columns(table: str) -> Dict[str, DataType]:\n    return {\n        row.column_name: parse_data_type(json.loads(row.data_type))\n        for row in snowflake_session().sql(f"show columns in table {table}").collect()\n    }\n\n\nclass DataTypeDict(TypedDict):\n    """Represent the `data_type` value in Snowflake `SHOW COLUMNS IN TABLE`."""\n\n    type: DataType\n    nullable: bool\n\n    # for type FIXED and TIME/TIMESTAMP\n    precision: NotRequired[int]\n    scale: NotRequired[int]\n\n    # for type TEXT and BINARY\n    length: NotRequired[int]\n    bytesLength: NotRequired[int]\n    fixed: NotRequired[bool]\n\n\ndef parse_data_type(data_type: DataTypeDict) -> ExtendedDataType:\n    if data_type["type"] == "FIXED" and data_type["scale"] == 0:\n        return "INTEGER"\n\n    return data_type["type"]\n\n\n@st.cache_data\ndef preview_table(table: str, limit: int = 5) -> pd.DataFrame:\n    return pd.DataFrame(snowflake_session().table(table).limit(limit).collect())\n\n\nclass Filters(BaseModelCacheKey):\n    mapping: Dict[str, List[str]] = Field(default_factory=dict)\n\n    def add(self, key: str, values: List[str]) -> None:\n        self.mapping[key] = values\n\n    def to_condition(self) -> f.Column:\n        """Return a Snowpark filter condition to be used in the `DataFrame.filter` or `DataFrame.where` methods."""\n        condition = f.lit(True)\n        for column, values in self.mapping.items():\n            condition &= f.col(column).in_(values)\n        return condition\n\n    def is_empty(self) -> bool:\n        return len(self.mapping) == 0\n\n\ndef drop_temporary_tables() -> None:\n    for table in fetch_tables.execute_without_cache():\n        if table.startswith("TMP_"):\n            snowflake_session().table(table).drop_table()\n\n    fetch_tables.clear_cache()\n')
    __stickytape_write_module('utils.py', b'from collections import defaultdict\nfrom typing import Callable, Dict, Iterable, List, Optional, Tuple, Type, TypeVar\n\nimport streamlit as st\nfrom inflection import pluralize as inflection_pluralize\nfrom pydantic import BaseModel\n\nT = TypeVar("T")\nK = TypeVar("K")\n\n\ndef pluralize(count: int, singular: str) -> str:\n    return f"{count} {inflection_pluralize(singular) if count > 1 else singular}"\n\n\ndef chunks(values: List[T], chunk_size: int) -> Iterable[List[T]]:\n    """Split the given values into multiple chunks of the given size."""\n    for index in range(0, len(values), chunk_size):\n        yield values[index : index + chunk_size]\n\n\nclass BaseModelCacheKey(BaseModel):\n    """Model that can be used as caching key in st.cache_data."""\n\n    def __reduce__(self) -> Tuple[Type, Tuple[str, ...]]:\n        """Function from pickle used by the hasher of st.cache_data."""\n        return (self.parse_raw, (self.json(),))\n\n\ndef groupby(values: List[T], key: Callable[[T], K]) -> Dict[K, List[T]]:\n    result = defaultdict(list)\n\n    for value in values:\n        result[key(value)].append(value)\n\n    return result\n')
    __stickytape_write_module('data/models.py', b'from abc import ABC, abstractmethod\nfrom typing import TYPE_CHECKING, Dict, List, Literal, NewType, Optional, Union\nfrom uuid import uuid4\n\nfrom pydantic import Field\n\nfrom data.helpers import repository\nfrom range_analysis_app import db\nfrom range_analysis_app.db import snowflake_session\nfrom utils import BaseModelCacheKey\n\nif TYPE_CHECKING:\n    from data.metric import Metric\n\n\nId = NewType("Id", str)\n\nEntityType = Literal["dimension", "activity", "metric"]\n\n\ndef get_uuid4() -> Id:\n    return str(uuid4())\n\n\nclass DomaBaseModel(BaseModelCacheKey, ABC):\n    @abstractmethod\n    def validate_entity(self) -> None:\n        """Raise ValueError if the current entity is invalid."""\n\n    @abstractmethod\n    def validation_item_name(self) -> str:\n        """Name of the item to be validated"""\n\n\nclass Entity(DomaBaseModel, ABC):\n    uid: Id = Field(default_factory=get_uuid4)\n    name: str\n\n    @classmethod\n    @abstractmethod\n    def get_type(cls) -> EntityType:\n        ...\n\n    @abstractmethod\n    def delete(self) -> None:\n        ...\n\n    def validate_entity(self) -> None:\n        if not bool(self.name):\n            raise ValueError(f"An entity name must be set.")\n\n    def validation_item_name(self) -> str:\n        return self.name\n\n\nclass DimensionActivityMapping(DomaBaseModel):\n    dim_id: Id\n    act_id: Id\n\n    main_table_id: Optional[Id]\n    joined_table_id: Optional[Id]\n\n    main_column: Optional[str]\n    joined_column: Optional[str]\n\n    @property\n    def dimension(self) -> Optional["Dimension"]:\n        return repository().get_entity("dimension", self.dim_id)\n\n    @property\n    def activity(self) -> Optional["Activity"]:\n        return repository().get_entity("activity", self.act_id)\n\n    @property\n    def main_table(self) -> Optional["DbTable"]:\n        return self._find_table(self.main_table_id)\n\n    @property\n    def joined_table(self) -> Optional["DbTable"]:\n        return self._find_table(self.joined_table_id)\n\n    @staticmethod\n    def _find_table(uid: Id) -> Optional["DbTable"]:\n        for table in repository().selected_tables:\n            if uid == table.uid:\n                return table\n\n    def validate_entity(self) -> None:\n        if not bool(self.main_table_id) or not bool(self.main_column):\n            raise ValueError(f"A main table must be set.")\n\n        if not bool(self.joined_table_id) or not bool(self.joined_column):\n            raise ValueError(f"A joined table must be set.")\n\n    def validation_item_name(self) -> str:\n        if self.dimension and self.activity:\n            return f"{self.dimension.name} <=> {self.activity.name}"\n        return "none"\n\n\nclass Dimension(Entity):\n    predefined: bool = False\n\n    @classmethod\n    def get_type(cls) -> EntityType:\n        return "dimension"\n\n    @staticmethod\n    def create(name: str) -> "Dimension":\n        dim = Dimension(name=name)\n        repository().dimensions.append(dim)\n        return dim\n\n    def delete(self) -> None:\n        repo = repository()\n        for activity in self.activities:\n            activity.unassign_dimension(self)\n\n        if table := self.db_table:\n            table.delete()\n\n        repo.dimensions.remove(self)\n\n    @property\n    def activities(self) -> List["Activity"]:\n        act_ids = [mapping.act_id for mapping in repository().dim_act_mappings if mapping.dim_id == self.uid]\n        return [act for act in repository().activities if act.uid in act_ids]\n\n    @property\n    def db_table(self) -> Optional["DbTable"]:\n        for table in repository().selected_tables:\n            if table.entity_uid == self.uid and table.entity_type == "dimension":\n                return table\n\n    def validate_entity(self) -> None:\n        super().validate_entity()\n\n        if self.db_table is None:\n            raise ValueError(f"Missing table for dimension {self.name}")\n\n\nclass Activity(Entity):\n    predefined: bool = False\n\n    @classmethod\n    def get_type(cls) -> EntityType:\n        return "activity"\n\n    @staticmethod\n    def create(name: str) -> "Activity":\n        act = Activity(name=name)\n        repository().activities.append(act)\n        return act\n\n    def delete(self) -> None:\n        for dimension in self.dimensions:\n            self.unassign_dimension(dimension)\n\n        if table := self.db_table:\n            table.delete()\n\n        for metric in self.metrics:\n            metric.delete()\n\n        repository().activities.remove(self)\n\n    @property\n    def dimensions(self) -> List[Dimension]:\n        dim_ids = [mapping.dim_id for mapping in repository().dim_act_mappings if mapping.act_id == self.uid]\n        return [dim for dim in repository().dimensions if dim.uid in dim_ids]\n\n    def assign_dimension(self, dim_id: Id) -> None:\n        mapping = DimensionActivityMapping(act_id=self.uid, dim_id=dim_id)\n        repository().dim_act_mappings.append(mapping)\n\n    def unassign_dimension(self, dim: Dimension) -> None:\n        repository().dim_act_mappings = [\n            mapping\n            for mapping in repository().dim_act_mappings\n            if mapping.act_id != self.uid or mapping.dim_id != dim.uid\n        ]\n        for metric in self.metrics:\n            metric.unassign_dimension(dim)\n\n    @property\n    def metrics(self) -> List["Metric"]:\n        return [metric for metric in repository().metrics if metric.act_id == self.uid]\n\n    @property\n    def mappings(self) -> List[DimensionActivityMapping]:\n        return [mapping for mapping in repository().dim_act_mappings if mapping.act_id == self.uid]\n\n    @property\n    def db_table(self) -> Optional["DbTable"]:\n        for table in repository().selected_tables:\n            if table.entity_uid == self.uid and table.entity_type == "activity":\n                return table\n\n    def validate_tables_and_mapping(self) -> List[str]:\n        """Return a list of error messages for each missing tables or mappings in the activity."""\n        errors = []\n        if self.db_table is None:\n            errors.append(f"Missing table for activity {self.name}")\n\n        for dim in self.dimensions:\n            if dim.db_table is None:\n                errors.append(f"Missing table for dimension {dim.name}")\n\n        for mapping in self.mappings:\n            try:\n                mapping.validate_entity()\n            except ValueError:\n                errors.append(f"Missing mapping: {mapping.validation_item_name()}")\n\n        return errors\n\n\nclass DbTable(DomaBaseModel):\n    uid: Id = Field(default_factory=get_uuid4)\n\n    table_name: str\n    table_schema: str\n    table_database: str\n\n    entity_uid: Id\n    entity_type: EntityType\n\n    columns: Dict[str, str] = {}\n\n    @staticmethod\n    def create(\n        table_name: str,\n        table_schema: str,\n        table_database: str,\n        columns: Dict[str, str],\n        entity: Entity,\n    ) -> "DbTable":\n        entity_uid = entity.uid\n        entity_type = entity.get_type()\n        tbl = DbTable(\n            table_name=table_name,\n            table_schema=table_schema,\n            table_database=table_database,\n            columns=columns,\n            entity_uid=entity_uid,\n            entity_type=entity_type,\n        )\n        repository().selected_tables.append(tbl)\n        return tbl\n\n    @property\n    def full_name(self) -> str:\n        return f"{self.table_database}.{self.table_schema}.{self.table_name}"\n\n    @property\n    def entity(self) -> Union[Activity, Dimension]:\n        return repository().get_entity(self.entity_type, self.entity_uid)\n\n    def delete(self) -> None:\n        repository().selected_tables.remove(self)\n\n        # Reset mapping with the table to delete\n        for mapping in repository().dim_act_mappings:\n            if self.uid in [mapping.main_table_id, mapping.joined_table_id]:\n                mapping.main_table_id = None\n                mapping.joined_table_id = None\n                mapping.main_column = None\n                mapping.joined_column = None\n\n        # Remove table columns from metrics\n        entity = self.entity\n\n        if isinstance(entity, Activity):\n            for metric in entity.metrics:\n                metric.columns = None\n\n        if isinstance(entity, Dimension):\n            for activity in entity.activities:\n                for metric in activity.metrics:\n                    metric.unassign_dimension(entity)\n\n    def validate_entity(self) -> None:\n        if snowflake_session().table(self.full_name).first() is None:\n            raise ValueError(f"Table \'{self.full_name}\' is empty or does not exist.")\n\n    def validation_item_name(self) -> str:\n        return self.full_name\n\n    def columns_of_type(self, data_types: List[db.DataType]) -> List[str]:\n        """Return the columns having one of the given types."""\n        return [col for col, data_type in self.columns.items() if data_type in data_types]\n')
    __stickytape_write_module('data/metric.py', b'import datetime\nfrom typing import Dict, List, Literal, Optional, Set, Tuple, get_args\n\nimport pandas as pd\nimport snowflake.snowpark.functions as f\nimport streamlit as st\nfrom pydantic import Field\nfrom snowflake import snowpark\n\nfrom data.helpers import repository\nfrom data.models import Activity, Dimension, DimensionActivityMapping, Entity, EntityType, Id\nfrom range_analysis_app import db\nfrom std_graphlib import TopologicalSorter\nfrom utils import BaseModelCacheKey, groupby\n\nAggMethod = Literal["sum", "count", "avg"]\nAGG_METHODS = get_args(AggMethod)\n\n\nclass MetricColumns(BaseModelCacheKey):\n    dimensions: List[str]\n    metric_column: str\n    timestamp: str\n    agg_method: Literal["sum", "count", "avg"] = "sum"\n\n    category: str  # Specific to Consumer Behavior Analysis\n\n    labels: Dict[str, str] = Field(default_factory=dict)\n\n    def remove_dimension_columns(self, dim_columns: Set[str]) -> None:\n        for dim_col in set(self.dimensions) & dim_columns:\n            self.dimensions.remove(dim_col)\n            self.labels.pop(dim_col, None)\n\n\nclass Metric(Entity):\n    act_id: Optional[Id]\n    columns: Optional[MetricColumns]\n\n    @classmethod\n    def get_type(cls) -> EntityType:\n        return "metric"\n\n    def validate_entity(self) -> None:\n        if not bool(self.columns):\n            raise ValueError(f"Metric columns must be set.")\n\n    @staticmethod\n    def create(name: str, act_id: Optional[str] = None) -> "Metric":\n        met = Metric(name=name, act_id=act_id)\n        repository().metrics.append(met)\n        return met\n\n    def delete(self) -> None:\n        repository().metrics.remove(self)\n\n    @property\n    def activity(self) -> Optional[Activity]:\n        return repository().get_entity("activity", self.act_id)\n\n    def unassign_dimension(self, dimension: Dimension):\n        dim_table = dimension.db_table\n        if not self.columns or not dim_table:\n            return\n\n        dim_columns = set(dim_table.columns.keys())\n        self.columns.remove_dimension_columns(dim_columns)\n\n    def dataframe(self) -> snowpark.DataFrame:\n        """Return a dataframe based on the metric activity joined with its dimensions."""\n        if not self.columns:\n            raise ValueError(f"No columns in metric {self.name}.")\n\n        if self.activity.validate_tables_and_mapping():\n            raise ValueError(f"Missing tables and mappings in activity {self.activity.name}.")\n\n        mappings = sorted_mappings(self.activity.mappings)\n\n        snowpark_tables: Dict[str, snowpark.Table] = {}\n        for mapping in mappings:\n            for table in [mapping.main_table, mapping.joined_table]:\n                if table.uid not in snowpark_tables:\n                    snowpark_tables[table.uid] = db.snowflake_session().table(table.full_name)\n\n        act_table = snowpark_tables[self.activity.db_table.uid]\n\n        result_dataframe = act_table\n\n        for mapping in sorted_mappings(self.activity.mappings):\n            main_table = snowpark_tables[mapping.main_table_id]\n            joined_table = snowpark_tables[mapping.joined_table_id]\n\n            result_dataframe = result_dataframe.join(\n                joined_table,\n                how="left",\n                on=main_table.col(mapping.main_column) == joined_table.col(mapping.joined_column),\n            )\n\n        def col_ref(column_name: str) -> snowpark.Column:\n            """Return a reference for the column in one of the given tables eg. my_table.my_column"""\n            for table in snowpark_tables.values():\n                if column_name in table.columns:\n                    return table.col(column_name)\n\n        cols = self.columns\n\n        return result_dataframe.select(\n            [\n                *(col_ref(col).alias(col) for col in cols.dimensions),\n                col_ref(cols.category).alias(cols.category),\n                f.to_date(col_ref(cols.timestamp)).alias(cols.timestamp),\n                col_ref(cols.metric_column).alias(cols.metric_column),\n            ]\n        )\n\n    @st.cache_data\n    def dimension_values(self, dimension: str, limit: int = 1000) -> List[str]:\n        assert dimension in self.columns.dimensions\n\n        rows = (\n            self.dataframe()\n            .group_by(dimension)\n            .agg(f.sum(self.columns.metric_column).alias("total"))\n            .sort(f.col("total").desc_nulls_last())\n            .limit(limit)\n            .collect()\n        )\n        return [row[dimension.upper()] for row in rows if row[dimension.upper()] is not None]\n\n    @st.cache_data\n    def preview_dataframe(self, limit: int = 10) -> pd.DataFrame:\n        data = pd.DataFrame(self.dataframe().limit(limit).collect())\n\n        columns = [self.columns.metric_column, self.columns.category] + self.columns.dimensions\n        renames = {col: f"{col} ({label})" for col, label in self.columns.labels.items()}\n        return (\n            data.set_index(self.columns.timestamp)[columns]\n            .rename(columns=renames)\n            .rename_axis(renames.get(self.columns.timestamp, self.columns.timestamp))\n        )\n\n    @st.cache_data\n    def date_range(self) -> Tuple[datetime.date, datetime.date]:\n        """Return the (min_date, max_date) of the metric."""\n        row = (\n            self.dataframe()\n            .select(f.min(self.columns.timestamp).alias("min_date"), f.max(self.columns.timestamp).alias("max_date"))\n            .first()\n        )\n        return row.MIN_DATE, row.MAX_DATE\n\n\ndef sorted_mappings(mappings: List[DimensionActivityMapping]) -> List[DimensionActivityMapping]:\n    """Return the mappings sorted by the order in which tables must be joined in SQL."""\n    # A graph is a dict of { node => preceding nodes }, so here we have { table to join => tables to load beforehand }\n    tables_graph = {\n        joined_table_id: [mapping.main_table_id for mapping in mappings]\n        for joined_table_id, mappings in groupby(mappings, key=lambda mapping: mapping.joined_table_id).items()\n    }\n    sorted_table_ids = list(TopologicalSorter(tables_graph).static_order())\n\n    def sort_by_main_table(mapping: DimensionActivityMapping) -> int:\n        return sorted_table_ids.index(mapping.main_table_id)\n\n    return sorted(mappings, key=sort_by_main_table)\n')
    __stickytape_write_module('std_graphlib.py', b'# Backport of the `graphlib` library that is available in python 3.9:\n# => https://docs.python.org/3/library/graphlib.html\n#\n# TODO: replace by `graphlib` from std once in python 3.9\n\n\n__all__ = ["TopologicalSorter", "CycleError"]\n\n_NODE_OUT = -1\n_NODE_DONE = -2\n\n\nclass _NodeInfo:\n    __slots__ = "node", "npredecessors", "successors"\n\n    def __init__(self, node):\n        # The node this class is augmenting.\n        self.node = node\n\n        # Number of predecessors, generally >= 0. When this value falls to 0,\n        # and is returned by get_ready(), this is set to _NODE_OUT and when the\n        # node is marked done by a call to done(), set to _NODE_DONE.\n        self.npredecessors = 0\n\n        # List of successor nodes. The list can contain duplicated elements as\n        # long as they\'re all reflected in the successor\'s npredecessors attribute.\n        self.successors = []\n\n\nclass CycleError(ValueError):\n    """Subclass of ValueError raised by TopologicalSorter.prepare if cycles\n    exist in the working graph.\n\n    If multiple cycles exist, only one undefined choice among them will be reported\n    and included in the exception. The detected cycle can be accessed via the second\n    element in the *args* attribute of the exception instance and consists in a list\n    of nodes, such that each node is, in the graph, an immediate predecessor of the\n    next node in the list. In the reported list, the first and the last node will be\n    the same, to make it clear that it is cyclic.\n    """\n\n    pass\n\n\nclass TopologicalSorter:\n    """Provides functionality to topologically sort a graph of hashable nodes"""\n\n    def __init__(self, graph=None):\n        self._node2info = {}\n        self._ready_nodes = None\n        self._npassedout = 0\n        self._nfinished = 0\n\n        if graph is not None:\n            for node, predecessors in graph.items():\n                self.add(node, *predecessors)\n\n    def _get_nodeinfo(self, node):\n        if (result := self._node2info.get(node)) is None:\n            self._node2info[node] = result = _NodeInfo(node)\n        return result\n\n    def add(self, node, *predecessors):\n        """Add a new node and its predecessors to the graph.\n\n        Both the *node* and all elements in *predecessors* must be hashable.\n\n        If called multiple times with the same node argument, the set of dependencies\n        will be the union of all dependencies passed in.\n\n        It is possible to add a node with no dependencies (*predecessors* is not provided)\n        as well as provide a dependency twice. If a node that has not been provided before\n        is included among *predecessors* it will be automatically added to the graph with\n        no predecessors of its own.\n\n        Raises ValueError if called after "prepare".\n        """\n        if self._ready_nodes is not None:\n            raise ValueError("Nodes cannot be added after a call to prepare()")\n\n        # Create the node -> predecessor edges\n        nodeinfo = self._get_nodeinfo(node)\n        nodeinfo.npredecessors += len(predecessors)\n\n        # Create the predecessor -> node edges\n        for pred in predecessors:\n            pred_info = self._get_nodeinfo(pred)\n            pred_info.successors.append(node)\n\n    def prepare(self):\n        """Mark the graph as finished and check for cycles in the graph.\n\n        If any cycle is detected, "CycleError" will be raised, but "get_ready" can\n        still be used to obtain as many nodes as possible until cycles block more\n        progress. After a call to this function, the graph cannot be modified and\n        therefore no more nodes can be added using "add".\n        """\n        if self._ready_nodes is not None:\n            raise ValueError("cannot prepare() more than once")\n\n        self._ready_nodes = [i.node for i in self._node2info.values() if i.npredecessors == 0]\n        # ready_nodes is set before we look for cycles on purpose:\n        # if the user wants to catch the CycleError, that\'s fine,\n        # they can continue using the instance to grab as many\n        # nodes as possible before cycles block more progress\n        cycle = self._find_cycle()\n        if cycle:\n            raise CycleError(f"nodes are in a cycle", cycle)\n\n    def get_ready(self):\n        """Return a tuple of all the nodes that are ready.\n\n        Initially it returns all nodes with no predecessors; once those are marked\n        as processed by calling "done", further calls will return all new nodes that\n        have all their predecessors already processed. Once no more progress can be made,\n        empty tuples are returned.\n\n        Raises ValueError if called without calling "prepare" previously.\n        """\n        if self._ready_nodes is None:\n            raise ValueError("prepare() must be called first")\n\n        # Get the nodes that are ready and mark them\n        result = tuple(self._ready_nodes)\n        n2i = self._node2info\n        for node in result:\n            n2i[node].npredecessors = _NODE_OUT\n\n        # Clean the list of nodes that are ready and update\n        # the counter of nodes that we have returned.\n        self._ready_nodes.clear()\n        self._npassedout += len(result)\n\n        return result\n\n    def is_active(self):\n        """Return ``True`` if more progress can be made and ``False`` otherwise.\n\n        Progress can be made if cycles do not block the resolution and either there\n        are still nodes ready that haven\'t yet been returned by "get_ready" or the\n        number of nodes marked "done" is less than the number that have been returned\n        by "get_ready".\n\n        Raises ValueError if called without calling "prepare" previously.\n        """\n        if self._ready_nodes is None:\n            raise ValueError("prepare() must be called first")\n        return self._nfinished < self._npassedout or bool(self._ready_nodes)\n\n    def __bool__(self):\n        return self.is_active()\n\n    def done(self, *nodes):\n        """Marks a set of nodes returned by "get_ready" as processed.\n\n        This method unblocks any successor of each node in *nodes* for being returned\n        in the future by a call to "get_ready".\n\n        Raises :exec:`ValueError` if any node in *nodes* has already been marked as\n        processed by a previous call to this method, if a node was not added to the\n        graph by using "add" or if called without calling "prepare" previously or if\n        node has not yet been returned by "get_ready".\n        """\n\n        if self._ready_nodes is None:\n            raise ValueError("prepare() must be called first")\n\n        n2i = self._node2info\n\n        for node in nodes:\n            # Check if we know about this node (it was added previously using add()\n            if (nodeinfo := n2i.get(node)) is None:\n                raise ValueError(f"node {node!r} was not added using add()")\n\n            # If the node has not being returned (marked as ready) previously, inform the user.\n            stat = nodeinfo.npredecessors\n            if stat != _NODE_OUT:\n                if stat >= 0:\n                    raise ValueError(f"node {node!r} was not passed out (still not ready)")\n                elif stat == _NODE_DONE:\n                    raise ValueError(f"node {node!r} was already marked done")\n                else:\n                    assert False, f"node {node!r}: unknown status {stat}"\n\n            # Mark the node as processed\n            nodeinfo.npredecessors = _NODE_DONE\n\n            # Go to all the successors and reduce the number of predecessors, collecting all the ones\n            # that are ready to be returned in the next get_ready() call.\n            for successor in nodeinfo.successors:\n                successor_info = n2i[successor]\n                successor_info.npredecessors -= 1\n                if successor_info.npredecessors == 0:\n                    self._ready_nodes.append(successor)\n            self._nfinished += 1\n\n    def _find_cycle(self):\n        n2i = self._node2info\n        stack = []\n        itstack = []\n        seen = set()\n        node2stacki = {}\n\n        for node in n2i:\n            if node in seen:\n                continue\n\n            while True:\n                if node in seen:\n                    # If we have seen already the node and is in the\n                    # current stack we have found a cycle.\n                    if node in node2stacki:\n                        return stack[node2stacki[node] :] + [node]\n                    # else go on to get next successor\n                else:\n                    seen.add(node)\n                    itstack.append(iter(n2i[node].successors).__next__)\n                    node2stacki[node] = len(stack)\n                    stack.append(node)\n\n                # Backtrack to the topmost stack entry with\n                # at least another successor.\n                while stack:\n                    try:\n                        node = itstack[-1]()\n                        break\n                    except StopIteration:\n                        del node2stacki[stack.pop()]\n                        itstack.pop()\n                else:\n                    break\n        return None\n\n    def static_order(self):\n        """Returns an iterable of nodes in a topological order.\n\n        The particular order that is returned may depend on the specific\n        order in which the items were inserted in the graph.\n\n        Using this method does not require to call "prepare" or "done". If any\n        cycle is detected, :exc:`CycleError` will be raised.\n        """\n        self.prepare()\n        while self.is_active():\n            node_group = self.get_ready()\n            yield from node_group\n            self.done(*node_group)\n')
    __stickytape_write_module('data/repository.py', b'from typing import TYPE_CHECKING, Dict, List, Optional, Union\n\nfrom pydantic import Field\nfrom pydantic.main import BaseModel\nfrom typing_extensions import Annotated\n\nfrom data.helpers import validate_state\nfrom data.metric import Metric\nfrom data.models import Activity, DbTable, Dimension, DimensionActivityMapping, Entity, EntityType, Id\nfrom widgets.kpis import TotalPurchaseValue\nfrom widgets.outlier_detection_widgets import PurchaseAnomaliesHeatmap\nfrom widgets.product_category_distribution_widgets import (\n    ProductCategoriesComparisonBarGraph,\n    ProductCategoryDistributionPieChart,\n)\nfrom widgets.purchasing_trend_over_time_widgets import PurchasingTrendsLineChart\n\nENTITY_TYPE_TO_COLLECTION: Dict[EntityType, str] = {\n    "dimension": "dimensions",\n    "activity": "activities",\n    "metric": "metrics",\n}\n\n\nWidgetType = Annotated[\n    Union[\n        ProductCategoryDistributionPieChart,\n        ProductCategoriesComparisonBarGraph,\n        PurchaseAnomaliesHeatmap,\n        PurchasingTrendsLineChart,\n        TotalPurchaseValue,\n    ],\n    Field(..., discriminator="widget_type"),\n]\n\n\nclass Repository(BaseModel):\n    dimensions: List[Dimension] = []\n    activities: List[Activity] = []\n    metrics: List[Metric] = []\n    selected_tables: List[DbTable] = []\n    dim_act_mappings: List[DimensionActivityMapping] = []\n    widgets: List[WidgetType] = []\n\n    def default_for_purchase_orders():\n        product = Dimension(name="Product", predefined=True)\n        purchase_order = Activity(name="Purchase Order", predefined=True)\n        mapping = DimensionActivityMapping(act_id=purchase_order.uid, dim_id=product.uid)\n        metric = Metric(name="Revenue", act_id=purchase_order.uid)\n\n        return Repository(\n            dimensions=[product],\n            activities=[purchase_order],\n            dim_act_mappings=[mapping],\n            metrics=[metric],\n            widgets=[\n                # KPIs\n                TotalPurchaseValue(metric=metric.copy(), grain="year"),\n                TotalPurchaseValue(metric=metric.copy(), grain="month"),\n                TotalPurchaseValue(metric=metric.copy(), grain="week"),\n                TotalPurchaseValue(metric=metric.copy(), grain="day"),\n                # Charts\n                PurchasingTrendsLineChart(metric=metric.copy()),\n                ProductCategoriesComparisonBarGraph(metric=metric.copy()),\n                ProductCategoryDistributionPieChart(metric=metric.copy()),\n                PurchaseAnomaliesHeatmap(metric=metric.copy()),\n            ],\n        )\n\n    def get_entity(self, entity_type: EntityType, uid: Id) -> Optional[Entity]:\n        collection_name = ENTITY_TYPE_TO_COLLECTION.get(entity_type)\n        if collection_name is None:\n            return None\n\n        for e in getattr(self, collection_name):\n            if e.uid == uid:\n                return e\n        return None\n\n    def is_valid(self) -> bool:\n        validations = [\n            validate_state(self.dimensions, "dimension", validate_each=False),\n            validate_state(self.activities, "activity", validate_each=False),\n            validate_state(self.metrics, "metric", validate_each=False),\n            validate_state(self.dimensions, "dimension", validate_each=True),\n            validate_state(self.activities, "activity", validate_each=True),\n            validate_state(self.dim_act_mappings, "mapping column", permit_empty=True),\n            validate_state(self.metrics, "metric", validate_each=True),\n            validate_state([widget.metric for widget in self.widgets], "metric", validate_each=True),\n        ]\n        return all(is_valid for is_valid, _ in validations)\n')
    __stickytape_write_module('widgets/__init__.py', b'\n')
    __stickytape_write_module('widgets/kpis.py', b'import datetime\nfrom datetime import date\nfrom typing import Dict, Literal, Optional, Tuple\n\nimport plotly.graph_objs as go\nimport snowflake.snowpark.functions as f\nimport streamlit as st\nfrom typing_extensions import Literal\n\nfrom data.metric import Metric\nfrom range_analysis_app import db\nfrom range_analysis_app.definitions.period import Period\nfrom range_analysis_app.definitions.time_series import GRAINS, Grain, TimeSeries\nfrom range_analysis_app.exploration.plotly_styles import COLORS, KPI_ANNOTATION_STYLE, KPI_LAYOUT\nfrom widgets.example_charts import example_kpi_metric\nfrom widgets.parameters import multiselect_dimension_filters, year_range_slider\nfrom widgets.widget import Widget, WidgetSize\n\n\nclass TotalPurchaseValue(Widget):\n    widget_kind: Literal["chart", "kpi", "text"] = "kpi"\n    widget_type: Literal["TotalPurchaseValue"] = "TotalPurchaseValue"\n    size: WidgetSize = "small"\n\n    # Parameters\n    metric: Metric\n    grain: Grain = "month"\n\n    # Filters\n    period: Optional[Period]\n    filters: db.Filters = db.Filters()\n\n    @staticmethod\n    def description() -> str:\n        return "Total Purchase Value"\n\n    @staticmethod\n    def example_figure() -> go.Figure:\n        return example_kpi_metric()\n\n    def default_title(self) -> str:\n        def period_over_period(grain: Grain) -> str:\n            letter = grain[0].upper()\n            return f"{letter}o{letter}"\n\n        return f"Revenue {period_over_period(self.grain)}"\n\n    def edit_parameters(self) -> None:\n        title = st.text_input("Title", value=self.title, placeholder=self.default_title())\n        grain = st.selectbox("Periodicity", GRAINS, index=GRAINS.index(self.grain))\n\n        st.markdown("#### Filters")\n        start_year, end_year = year_range_slider(self.metric, self.period)\n        filters = multiselect_dimension_filters(self.metric, self.filters)\n\n        def apply_changes() -> None:\n            self.title = title\n            self.grain = grain\n            self.period = Period(start=date(start_year, 1, 1), end=date(end_year, 12, 31))\n            self.filters = filters\n\n        st.button("Apply", use_container_width=True, on_click=apply_changes)\n\n    def figure(self) -> go.Figure:\n        current, previous = fetch_total_values(self.metric, self.grain, self.filters, self.period)\n\n        title = self.displayed_title()\n        diff_percent = (current["VALUE"] / previous["VALUE"] - 1) * 100\n\n        delta_arrow = "\xe2\x96\xb2" if diff_percent > 0 else "\xe2\x96\xbc"\n        delta_color = COLORS["indicator-increasing"] if diff_percent > 0 else COLORS["indicator-decreasing"]\n\n        return (\n            go.Figure(layout=KPI_LAYOUT)\n            .add_annotation(\n                text=title,\n                yanchor="top",\n                xshift=12,\n                yshift=-4,\n                font=dict(size=16, color=COLORS["indicator-text"]),\n                **KPI_ANNOTATION_STYLE,\n            )\n            .add_annotation(\n                text=f\'${current["VALUE"]:,.0f}\',\n                xshift=12,\n                yshift=-24,\n                font=dict(size=36, color=COLORS["indicator-text"]),\n                **KPI_ANNOTATION_STYLE,\n            )\n            .add_annotation(\n                text=f"{delta_arrow} {diff_percent:.0f}%",\n                xshift=12,\n                yshift=-72,\n                font=dict(size=14, color=delta_color),\n                **KPI_ANNOTATION_STYLE,\n            )\n            .update_xaxes(showticklabels=False, showgrid=False, zeroline=False)\n            .update_yaxes(showticklabels=False, showgrid=False, zeroline=False)\n        )\n\n\n@st.cache_data\ndef fetch_total_values(\n    metric: Metric,\n    grain: Grain,\n    filters: db.Filters,\n    period: Optional[Period],\n) -> Tuple[float, float]:\n    metric_column = metric.columns.metric_column\n\n    current, previous = (\n        TimeSeries(metric=metric, grain=grain)\n        .dataframe()\n        .filter(filters.to_condition())\n        .filter(f.col("period").between(period.start, period.end) if period else f.lit(True))\n        .group_by("period")\n        .agg(f.sum(metric_column).alias("value"))\n        .sort("period", ascending=False)\n        .first(2)\n    )\n    return current, previous\n\n\ndef period_text(grain: Grain, period: datetime.date):\n    GRAIN_FORMATS: Dict[Grain, str] = {\n        "day": "%Y-%m-%d",\n        "week": "Week %W",\n        "month": "%b %Y",\n        "quarter": "Q%q",\n        "year": "%Y",\n    }\n    return period.strftime(GRAIN_FORMATS[grain])\n')
    __stickytape_write_module('range_analysis_app/definitions/__init__.py', b'')
    __stickytape_write_module('range_analysis_app/definitions/period.py', b'import datetime\nfrom typing import Literal\n\nimport pandas as pd\n\nfrom utils import BaseModelCacheKey\n\nPeriodFrequency = Literal["W", "M", "Y", "year-weeks"]\n\n\nclass Period(BaseModelCacheKey):\n    """Period of time between two dates."""\n\n    start: datetime.date\n    end: datetime.date\n\n    @staticmethod\n    def from_pandas(period: pd.Period) -> "Period":\n        return Period(start=period.start_time, end=period.end_time)\n\n    def from_year(year: int) -> "Period":\n        return Period(start=datetime.date(year, 1, 1), end=datetime.date(year, 12, 31))\n\n    @staticmethod\n    def from_date(date: datetime.date, freq: PeriodFrequency) -> "Period":\n        if freq == "year-weeks":\n            return period_of_year_weeks(date.year)\n\n        return Period.from_pandas(pd.Timestamp(date).to_period(freq))\n\n\ndef period_of_year_weeks(year: int) -> Period:\n    """Return the start and end date of the first and last weeks of the given year."""\n    year_period = pd.Period(year, freq="Y")\n\n    first_week = year_period.start_time.to_period("W")\n    last_week = year_period.end_time.to_period("W")\n\n    if first_week.week != 1:  # the last week of previous year\n        first_week += 1\n\n    if last_week.week == 1:  # the first week of next year\n        last_week -= 1\n\n    return Period(start=first_week.start_time.floor("D"), end=last_week.end_time.floor("D"))\n')
    __stickytape_write_module('range_analysis_app/definitions/time_series.py', b'from typing import Literal, get_args\n\nimport snowflake.snowpark as snowpark\nimport snowflake.snowpark.functions as f\n\nfrom data.metric import Metric\nfrom range_analysis_app.definitions.definition import DataframeDefinition\n\nGrain = Literal["day", "week", "month", "quarter", "year"]\nGRAINS = get_args(Grain)\n\n\nclass TimeSeries(DataframeDefinition):\n    metric: Metric\n    grain: Grain\n\n    def dataframe(self) -> snowpark.DataFrame:\n        cols = self.metric.columns\n        period_column = f.date_trunc(self.grain, cols.timestamp).alias("period")\n\n        return (\n            self.metric.dataframe()\n            .select(cols.dimensions + [cols.metric_column, period_column])\n            .group_by(cols.dimensions + [period_column.get_name()])\n            .agg(getattr(f, cols.agg_method)(cols.metric_column).alias(cols.metric_column))\n        )\n')
    __stickytape_write_module('range_analysis_app/definitions/definition.py', b'import hashlib\nfrom abc import abstractmethod\nfrom typing import Generic, Literal, TypeVar\n\nimport snowflake.snowpark as snowpark\nfrom pydantic import BaseModel\n\nimport range_analysis_app.db as db\nfrom utils import BaseModelCacheKey\n\n\ndef hash_json(model: BaseModel) -> int:\n    """Return a constant hash representing the given Pydantic model."""\n    return int(hashlib.sha1(model.json().encode()).hexdigest()[:10], 16)\n\n\nclass DataframeDefinition(BaseModelCacheKey):\n    """Represent a Snowpark calculation resulting in a dataframe.\n\n    This definition is hashable to be able to cache the result in Streamlit.\n    """\n\n    __hash__ = hash_json\n\n    @abstractmethod\n    def dataframe(self) -> snowpark.DataFrame:\n        ...\n\n\nTDefinition = TypeVar("TDefinition", bound=DataframeDefinition)\n\n\nclass ResultTable(Generic[TDefinition], BaseModel):\n    """Table stored from a Snowpark Dataframe."""\n\n    __hash__ = hash_json\n\n    table_name: str\n    definition: TDefinition\n\n    def table(self) -> snowpark.Table:\n        return db.snowflake_session().table(self.table_name)\n\n\ndef generate_table(\n    definition: TDefinition,\n    table_name: str,\n    table_type: Literal["", "temporary"] = "",\n) -> ResultTable[TDefinition]:\n    """Generate a table for the given dataframe and return the table name."""\n    definition.dataframe().write.save_as_table(table_name, table_type=table_type, mode="overwrite")\n    return ResultTable(table_name=table_name, definition=definition)\n')
    __stickytape_write_module('range_analysis_app/exploration/__init__.py', b'')
    __stickytape_write_module('range_analysis_app/exploration/plotly_styles.py', b'import plotly.express as px\nimport plotly.graph_objects as go\n\nGRADIENT_COLOR = [\n    "#1a72c0",\n    "#168bf4",\n    "#5cb2ff",\n    "#7cbbf5",\n    "#8a96ff",\n    "#4c5ded",\n    "#3e49a7",\n    "#352a92",\n    "#110670",\n]\n\n\nCOLORS = {\n    "text": "#3e49a7",\n    "ticks": "#aaa8b8",\n    "background": "#f0f2f6",\n    "plot-background": "#ffffff",\n    "selected-background": "#fff0f0",\n    "line-color": "#4c5ded",\n    "line-background": "#9cdcf7",\n    "highlight": "#BD2593",\n    "indicator-text": "#ffffff",\n    "indicator-background": "#2d3579",\n    "indicator-increasing": "#2fed6a",\n    "indicator-decreasing": "#fd3131",\n    "bar-chart-a": "#7cbbf5",\n    "bar-chart-b": "#110670",\n}\n\n# Doc: https://plotly.com/python/configuration-options\nPLOTLY_CONFIG = {\n    "displayModeBar": False,\n}\n\n# Doc: https://plotly.com/python-api-reference/generated/plotly.graph_objects.layout.html#plotly.graph_objects.layout.Shape\nPLOT_BORDER = go.layout.Shape(\n    type="rect",\n    xref="paper",\n    yref="paper",\n    x0=0,\n    y0=0,\n    x1=1,\n    y1=1,\n    line={"width": 1, "color": COLORS["text"]},\n)\n\n# Doc: https://plotly.com/python-api-reference/generated/plotly.graph_objects.Layout.html\nPLOT_LAYOUT = go.Layout(\n    height=420,\n    margin={"t": 46, "b": 32, "l": 32, "r": 32, "pad": 0, "autoexpand": True},\n    font={\n        "family": "Source Sans Pro",\n        "color": COLORS["text"],\n    },\n    showlegend=True,\n    paper_bgcolor=COLORS["background"],\n    plot_bgcolor=COLORS["plot-background"],\n    title={\n        "pad": dict(t=16, b=0, l=16, r=0),\n        "font": {"color": COLORS["text"]},\n        "x": 0,\n        "y": 1,\n        "xanchor": "left",\n        "yanchor": "top",\n    },\n    xaxis={\n        "title": {"font": {"color": COLORS["ticks"], "size": 14}, "standoff": 16},\n        "showgrid": True,\n        "color": COLORS["ticks"],\n        "ticks": "outside",\n        "tickcolor": COLORS["ticks"],\n        "tickfont": {"size": 12, "color": COLORS["ticks"], "family": "Arial"},\n        "dtick": "M12",\n    },\n    yaxis={\n        "title": {"font": {"color": COLORS["ticks"]}, "standoff": 16},\n        "showgrid": True,\n        "color": COLORS["ticks"],\n        "ticks": "outside",\n        "tickcolor": COLORS["ticks"],\n        "tickfont": {"size": 14, "color": COLORS["ticks"]},\n    },\n    legend={\n        "font": {"color": COLORS["text"]},\n        "x": 1,\n        "y": 1.125,\n        "xanchor": "right",\n        "yanchor": "top",\n        "orientation": "h",\n    },\n)\n\n\n# Doc: https://plotly.com/python-api-reference/generated/plotly.graph_objects.Box.html\nBOXPLOT_STYLE = go.Box(\n    fillcolor=COLORS["line-background"],\n    line={"color": COLORS["line-color"]},\n)\n\n\nSCATTER_STYLE = go.Scatter(\n    hovertemplate="<b>%{y}</b><br>%{x}<extra></extra>",\n    # margin={"line": {"width": 0}, "size": 6},\n    line={"width": 1, "color": COLORS["line-color"]},\n)\n\nBAR_STYLE = go.Bar(hovertemplate="<b>%{y}</b><br>%{x}<extra></extra>")\n\n# Doc: https://plotly.com/python/reference/pie\nPIE_STYLE = go.Pie(\n    marker_colors=list(reversed(GRADIENT_COLOR)),\n    hoverinfo="label",\n)\nPIE_LAYOUT = go.Layout(\n    # margin={"t": 46, "b": 32, "l": 32, "r": 32},\n    legend={\n        "x": 0.5,\n        "xanchor": "center",\n        "y": -0.1,\n        "yanchor": "middle",\n        "orientation": "h",\n    },\n)\n\nHEATMAP_STYLE = go.Heatmap(\n    # colorscale=["#cbe2fa", "#5cb2ff", "#110670"],\n    autocolorscale=True,\n    hovertemplate="<b>%{z}</b><br>%{y} - %{x}<extra></extra>",\n    texttemplate="%{z}",\n)\n\n\n# Style of an example chart\nEXAMPLE_LAYOUT = go.Layout(\n    height=150,\n    margin={"t": 15, "b": 15, "l": 15, "r": 15},\n    showlegend=False,\n    xaxis={"title": None},\n    yaxis={"title": None},\n)\nEXAMPLE_COLORS = px.colors.sequential.Blues_r\n\n\n# Styles of a selected chart\nSELECTED_STYLE = go.Layout(\n    # title={"font": {"color": COLORS["highlight"]}},\n    # paper_bgcolor=COLORS["selected-background"],\n    shapes=[PLOT_BORDER.update(go.layout.Shape(line={"width": 3, "color": COLORS["highlight"]}))],\n)\n\nINDICATOR_LAYOUT = go.Layout(\n    height=100,\n    font_family="Source Sans Pro",\n    font={"color": COLORS["indicator-text"]},\n    paper_bgcolor=COLORS["indicator-background"],\n    margin={"t": 150, "l": 12},\n)\nINDICATOR_STYLE = go.Indicator(\n    mode="number+delta",\n    title={\n        "align": "left",\n        "font": {"size": 16},\n    },\n    align="left",\n    number={\n        "font": {"size": 36},\n        "valueformat": "$,.0f",\n    },\n    delta={\n        "font": {"size": 14},\n        "valueformat": "$,.0f",\n        "position": "bottom",\n        "increasing": {\n            "color": COLORS["indicator-increasing"],\n            "symbol": "\xe2\x86\x91 ",\n        },\n        "decreasing": {\n            "color": COLORS["indicator-decreasing"],\n            "symbol": "\xe2\x86\x93 ",\n        },\n    },\n)\nINDICATOR_SELECTED_STYLE = {\n    "paper_bgcolor": COLORS["highlight"],\n}\n\n\nKPI_LAYOUT = go.Layout(\n    height=96,\n    font_family="Source Sans Pro",\n    plot_bgcolor=COLORS["indicator-background"],\n    margin=dict(l=0, r=0, t=0, b=0),\n)\nKPI_ANNOTATION_STYLE = dict(borderpad=0, showarrow=False, xref="paper", yref="paper", x=0, y=1)\n')
    __stickytape_write_module('widgets/example_charts.py', b'import itertools\n\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.graph_objs as go\n\nfrom range_analysis_app.exploration.plotly_styles import (\n    EXAMPLE_COLORS,\n    EXAMPLE_LAYOUT,\n    INDICATOR_LAYOUT,\n    INDICATOR_STYLE,\n    PLOT_LAYOUT,\n)\n\n\ndef example_pie_chart() -> go.Figure:\n    df = pd.DataFrame(\n        {\n            "Product Category": list("ABCDE"),\n            "Percentage": np.random.randint(100, size=5),\n        }\n    )\n    return (\n        px.pie(df, names="Product Category", values="Percentage", title=" ", color_discrete_sequence=EXAMPLE_COLORS)\n        .update_layout(PLOT_LAYOUT)\n        .update_layout(EXAMPLE_LAYOUT)\n    )\n\n\ndef example_bar_comparison_chart() -> go.Figure:\n    return (\n        go.Figure(\n            layout=go.Layout(title=""),\n            data=[\n                go.Bar(name="2022", x=list("ABCDE"), y=np.random.randint(75, size=5) + 25),\n                go.Bar(name="2023", x=list("ABCDE"), y=np.random.randint(75, size=5) + 25),\n            ],\n        )\n        .update_layout(PLOT_LAYOUT)\n        .update_layout(EXAMPLE_LAYOUT)\n    )\n\n\ndef example_bar_chart() -> go.Figure:\n    df = pd.DataFrame(\n        {\n            "Product Category": list("ABCDEFGHIJ"),\n            "Purchasing Volume": np.random.randint(100, size=10),\n        }\n    )\n    return (\n        px.bar(df, x="Product Category", y="Purchasing Volume", title=" ", color_discrete_sequence=EXAMPLE_COLORS)\n        .update_layout(PLOT_LAYOUT)\n        .update_layout(EXAMPLE_LAYOUT)\n    )\n\n\ndef example_box_chart() -> go.Figure:\n    df = pd.DataFrame(\n        {\n            "Product Category": itertools.chain(*([category] * 10 for category in list("ABCDEFGHIJ"))),\n            "Purchase Amount": np.random.randint(100, size=100),\n        }\n    )\n    return (\n        px.box(df, x="Product Category", y="Purchase Amount", title=" ", color_discrete_sequence=EXAMPLE_COLORS)\n        .update_layout(PLOT_LAYOUT)\n        .update_layout(EXAMPLE_LAYOUT)\n    )\n\n\ndef example_line_chart() -> go.Figure:\n    df = pd.DataFrame(\n        {\n            "month": pd.date_range(end="2023-01-01", periods=30, freq="MS"),\n            "trend": np.random.randint(100, size=30) + 50,\n        }\n    )\n    return (\n        px.line(df, x="month", y="trend", title=" ", range_y=[0, 200], color_discrete_sequence=EXAMPLE_COLORS)\n        .update_layout(PLOT_LAYOUT)\n        .update_layout(EXAMPLE_LAYOUT)\n    )\n\n\ndef example_area_chart() -> go.Figure:\n    df = pd.DataFrame(\n        {\n            "quarter": pd.date_range(end="2023-01-01", periods=24, freq="Q"),\n            "trend": np.random.randint(100, size=24) + 50,\n        }\n    )\n    return (\n        px.area(df, x="quarter", y="trend", title=" ", color_discrete_sequence=EXAMPLE_COLORS)\n        .update_layout(PLOT_LAYOUT)\n        .update_layout(EXAMPLE_LAYOUT)\n    )\n\n\ndef example_heatmap_chart() -> go.Figure:\n    scores = np.concatenate((np.random.randint(50, size=45), np.random.randint(10, size=5) + 90))\n    np.random.shuffle(scores)\n\n    df = pd.DataFrame(\n        {\n            "X": list("ABCDE") * 10,\n            "Y": itertools.chain(*([category] * 10 for category in list("ABCDE"))),\n            "score": scores,\n        }\n    )\n    return (\n        go.Figure(\n            layout={"title": " "},\n            data=go.Heatmap(\n                x=df["X"],\n                y=df["Y"],\n                z=df["score"],\n                # colorscale=list(reversed(EXPRESS_COLORS)),\n                autocolorscale=True,\n                hovertext=df["X"] + " - " + df["Y"] + ": " + df["score"].astype(str),\n                hoverinfo="text",\n                colorbar=dict(title="Score"),\n            ),\n        )\n        .update_layout(PLOT_LAYOUT)\n        .update_layout(EXAMPLE_LAYOUT)\n    )\n\n\ndef example_kpi_metric() -> go.Figure:\n    return go.Figure(\n        layout=INDICATOR_LAYOUT,\n        data=go.Indicator(\n            value=30000,\n            delta=go.indicator.Delta(reference=30000 * 0.90),\n            title={"text": "Average per Month"},\n        ).update(INDICATOR_STYLE),\n    )\n')
    __stickytape_write_module('widgets/parameters.py', b'from typing import Optional, Tuple\n\nimport streamlit as st\n\nfrom data.helpers import repository\nfrom data.metric import Metric\nfrom range_analysis_app import db\nfrom range_analysis_app.definitions.period import Period\n\n\ndef year_range_slider(metric: Metric, period: Optional[Period] = None) -> Tuple[int, int]:\n    """Slider to select the range of years."""\n    min_date, max_date = metric.date_range()\n    return st.slider(\n        "Time Period",\n        min_value=min_date.year,\n        max_value=max_date.year,\n        value=(period.start.year, period.end.year) if period else (min_date.year, max_date.year),\n    )\n\n\ndef metric_selection(metric: Metric) -> Metric:\n    """Selectbox among all metrics."""\n    return st.selectbox(\n        "Metric",\n        options=repository().metrics,\n        index=repository().metrics.index(metric),\n        format_func=lambda metric: metric.name,\n    )\n\n\ndef multiselect_dimension_filters(metric: Metric, current_filters: db.Filters) -> db.Filters:\n    """List of multiselect filters for each dimension in the metric."""\n    filters = db.Filters()\n\n    for dimension in metric.columns.dimensions:\n        label = metric.columns.labels.get(dimension, dimension)\n\n        values = st.multiselect(\n            label,\n            metric.dimension_values(dimension),\n            default=current_filters.mapping.get(dimension),\n        )\n        if values:\n            filters.add(dimension, values)\n\n    return filters\n')
    __stickytape_write_module('widgets/widget.py', b'from abc import abstractmethod\nfrom typing import Literal, Optional\n\nimport plotly.graph_objects as go\n\nfrom range_analysis_app.definitions.time_series import GRAINS\nfrom utils import BaseModelCacheKey\n\nWidgetSize = Literal["small", "medium", "large"]\n\n\nclass Widget(BaseModelCacheKey):\n    widget_kind: Literal["chart", "kpi", "text"] = "chart"\n    size: WidgetSize = "medium"\n\n    title: str = ""\n\n    @staticmethod\n    @abstractmethod\n    def description() -> str:\n        """Description of the widget in the gallery."""\n\n    @abstractmethod\n    def default_title(self) -> str:\n        """Default title inferred from parameters."""\n\n    def displayed_title(self) -> str:\n        """Either the title defined by the user or the one inferred from parameters."""\n        return (self.title or self.default_title()).strip()\n\n    @staticmethod\n    @abstractmethod\n    def example_figure() -> go.Figure:\n        """Return an example plotly figure showing how the widget look like."""\n\n    @abstractmethod\n    def edit_parameters(self) -> None:\n        """Render a form for editing the widget parameters."""\n\n    @abstractmethod\n    def figure(self) -> go.Figure:\n        """Return the plotly figure with the defined parameters."""\n')
    __stickytape_write_module('widgets/outlier_detection_widgets.py', b'import calendar\nfrom datetime import date\nfrom textwrap import dedent\nfrom typing import Literal, Optional, Tuple\n\nimport pandas as pd\nimport plotly.graph_objs as go\nimport snowflake.snowpark.functions as f\nimport streamlit as st\n\nfrom data.metric import Metric\nfrom range_analysis_app import db\nfrom range_analysis_app.definitions.period import Period\nfrom range_analysis_app.definitions.range_comparison import RANGE_PERIODICITIES, RANGE_PERIODICITIES_CONFIGS\nfrom range_analysis_app.exploration.plotly_styles import HEATMAP_STYLE, PLOT_LAYOUT\nfrom widgets.example_charts import example_heatmap_chart\nfrom widgets.parameters import multiselect_dimension_filters, year_range_slider\nfrom widgets.product_category_distribution_widgets import retrieve_category_column\nfrom widgets.widget import Widget, WidgetSize\n\n\nclass PurchaseAnomaliesHeatmap(Widget):\n    widget_kind: Literal["chart", "kpi", "text"] = "chart"\n    widget_type: Literal["PurchaseAnomaliesHeatmap"] = "PurchaseAnomaliesHeatmap"\n    size: WidgetSize = "large"\n\n    # Parameters\n    metric: Metric\n    x_col: str = "day_of_week"\n\n    # Filters\n    period: Optional[Period]\n    filters: db.Filters = db.Filters()\n\n    @staticmethod\n    def description() -> str:\n        return "Visualizes purchase anomalies"\n\n    @staticmethod\n    def example_figure() -> go.Figure:\n        return example_heatmap_chart()\n\n    def default_title(self) -> str:\n        return "Purchase Variant - Product"\n\n    def edit_parameters(self) -> None:\n        title = st.text_input("Title", value=self.title, placeholder=self.default_title())\n\n        # dim_columns = self.metric.columns.dimensions + list(RANGE_PERIODICITIES)\n        # x_col = st.selectbox("X column", options=dim_columns, index=dim_columns.index(self.x_col))\n        # y_col = st.selectbox("Y column", options=dim_columns, index=dim_columns.index(self.y_col))\n\n        PERIODICITIES = ["day_of_week", "month", "quarter"]\n        x_col = st.selectbox(\n            "Period",\n            options=PERIODICITIES,\n            index=PERIODICITIES.index(self.x_col),\n            format_func=lambda text: text.capitalize().replace("_", " "),\n        )\n\n        st.markdown("#### Filters")\n        start_year, end_year = year_range_slider(self.metric, self.period)\n        filters = multiselect_dimension_filters(self.metric, self.filters)\n\n        def apply_changes() -> None:\n            self.title = title\n            self.x_col = x_col\n            # self.y_col = y_col\n            self.period = Period(start=date(start_year, 1, 1), end=date(end_year, 12, 31))\n            self.filters = filters\n\n        st.button("Apply", use_container_width=True, on_click=apply_changes)\n\n    def figure(self) -> go.Figure:\n        metric = self.metric\n        y_col = metric.columns.category\n\n        df = fetch_correlation(self.metric, self.x_col, y_col, self.filters, self.period)\n\n        x = df[self.x_col.upper()]\n        y = df[y_col.upper()]\n        z = df[metric.columns.metric_column]\n\n        if self.x_col in PERIOD_NAMES:\n            x = x.map(dict(enumerate(PERIOD_NAMES[self.x_col])))\n\n        return go.Figure(\n            layout=go.Layout(title=self.displayed_title()),\n            data=go.Heatmap(x=x, y=y, z=z).update(HEATMAP_STYLE),\n        ).update_layout(PLOT_LAYOUT)\n\n\n@st.cache_data\ndef fetch_correlation(\n    metric: Metric,\n    x_column: str,\n    y_column: str,\n    filters: db.Filters,\n    period: Optional[Period] = None,\n) -> pd.DataFrame:\n    """Fetch the dataframe with [X, Y, Metric] columns."""\n    cols = metric.columns\n\n    def category_column(col: str) -> f.Column:\n        """Either use the given dimension column or the truncated date column"""\n        if col in RANGE_PERIODICITIES_CONFIGS:\n            config = RANGE_PERIODICITIES_CONFIGS[col]\n            return config["period_function"](cols.timestamp).alias(col)\n\n        return f.col(col)\n\n    x_col = category_column(x_column)\n    y_col = category_column(y_column)\n\n    return (\n        metric.dataframe()\n        .select([x_col, y_col, cols.metric_column])\n        .filter(filters.to_condition())\n        .filter(f.col(cols.timestamp).between(period.start, period.end) if period else f.lit(True))\n        .group_by([x_col.get_name(), y_col.get_name()])\n        .agg(getattr(f, cols.agg_method)(cols.metric_column).alias(cols.metric_column))\n        .sort([x_col.get_name(), y_col.get_name()])\n        .to_pandas()\n    )\n\n\nPERIOD_NAMES = {\n    "day_of_week": [\n        "Sunday",\n        "Monday",\n        "Tuesday",\n        "Wednesday",\n        "Thursday",\n        "Friday",\n        "Saturday",\n    ],\n    "month": calendar.month_name,\n    "quarter": ["", "Q1", "Q2", "Q3", "Q4"],\n}\n')
    __stickytape_write_module('range_analysis_app/definitions/range_comparison.py', b'from datetime import date\nfrom typing import Any, Dict, List, Literal, get_args\n\nimport pandas as pd\nimport snowflake.snowpark as snowpark\nimport snowflake.snowpark.functions as f\n\nfrom data.metric import Metric\nfrom range_analysis_app import db\nfrom range_analysis_app.definitions.definition import DataframeDefinition\nfrom range_analysis_app.definitions.period import Period, PeriodFrequency\nfrom range_analysis_app.definitions.time_series import TimeSeries\n\nRangePeriodicity = Literal["day_of_month", "day_of_week", "day_of_year", "week", "month", "quarter"]\nRANGE_PERIODICITIES = get_args(RangePeriodicity)\n\n\nclass RangeComparison(DataframeDefinition):\n    metric: Metric\n    range_periodicity: RangePeriodicity\n    historical_dates: Period\n    current_period_date: date\n    filters: db.Filters\n\n    def dataframe(self) -> snowpark.DataFrame:\n        metric_col = self.metric.columns.metric_column\n        historical_ranges = aggregate_over_ranges(\n            self.metric,\n            self.range_periodicity,\n            date_range=self.historical_dates,\n            aggregations=[\n                f.min(metric_col).alias("minimum"),\n                f.percentile_cont(0.25).within_group(metric_col).alias("lower_quartile"),\n                f.median(metric_col).alias("median"),\n                f.percentile_cont(0.75).within_group(metric_col).alias("upper_quartile"),\n                f.max(metric_col).alias("maximum"),\n            ],\n            filters=self.filters,\n        )\n\n        current_ranges = aggregate_over_ranges(\n            self.metric,\n            self.range_periodicity,\n            date_range=self.current_period(),\n            aggregations=[\n                f.any_value(metric_col).alias("current_value"),\n            ],\n            filters=self.filters,\n        )\n\n        return historical_ranges.join(current_ranges, on="range_period", how="left")\n\n    def current_period(self) -> Period:\n        PERIOD_FREQUENCIES: Dict[RangePeriodicity, PeriodFrequency] = {\n            "day_of_week": "W",\n            "day_of_month": "M",\n            "day_of_year": "Y",\n            "week": "year-weeks",\n            "month": "Y",\n            "quarter": "Y",\n        }\n        return Period.from_date(self.current_period_date, freq=PERIOD_FREQUENCIES[self.range_periodicity])\n\n\nRANGE_PERIODICITIES_CONFIGS: Dict[RangePeriodicity, Dict[str, Any]] = {\n    "day_of_week": {"period_function": f.dayofweek, "grain": "day"},\n    "day_of_month": {"period_function": f.dayofmonth, "grain": "day"},\n    "day_of_year": {"period_function": f.dayofyear, "grain": "day"},\n    "week": {"period_function": f.weekofyear, "grain": "week"},\n    "month": {"period_function": f.month, "grain": "month"},\n    "quarter": {"period_function": f.quarter, "grain": "quarter"},\n}\n\n\ndef aggregate_over_ranges(\n    metric: Metric,\n    range_periodicity: RangePeriodicity,\n    date_range: Period,\n    aggregations: List[f.Column],\n    filters: db.Filters,\n) -> snowpark.DataFrame:\n    """Aggregate the given metric over the periods of a periodicity.\n\n    For example, to aggregate each month between 2010 and 2020, outputting 12 rows.\n    """\n\n    range_config = RANGE_PERIODICITIES_CONFIGS[range_periodicity]\n    period_column = range_config["period_function"]("period").alias("range_period")\n\n    cols = metric.columns\n    return (\n        TimeSeries(metric=metric, grain=range_config["grain"])\n        .dataframe()\n        .filter(filters.to_condition())\n        .filter(f.col("period").between(date_range.start, date_range.end))\n        .select([cols.metric_column, period_column])\n        .group_by([period_column.get_name()])\n        .agg(aggregations)\n        .sort(period_column.get_name())\n    )\n')
    __stickytape_write_module('widgets/product_category_distribution_widgets.py', b'from datetime import date\nfrom typing import Literal, Optional, get_args\n\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport snowflake.snowpark.functions as f\nimport streamlit as st\n\nfrom data.helpers import repository\nfrom data.metric import Metric\nfrom range_analysis_app import db\nfrom range_analysis_app.definitions.period import Period\nfrom range_analysis_app.exploration.plotly_styles import BAR_STYLE, COLORS, PIE_LAYOUT, PIE_STYLE, PLOT_LAYOUT\nfrom widgets.example_charts import example_bar_comparison_chart, example_pie_chart\nfrom widgets.parameters import multiselect_dimension_filters, year_range_slider\nfrom widgets.widget import Widget, WidgetSize\n\nViewingMode = Literal["percent", "value"]\nVIEWING_MODES = get_args(ViewingMode)\n\nSortOrder = Literal["desc", "asc"]\nSORT_LABELS = {"desc": "Bestselling", "asc": "Underperforming"}\n\n\nclass ProductCategoryDistributionPieChart(Widget):\n    widget_kind: Literal["chart", "kpi", "text"] = "chart"\n    widget_type: Literal["ProductCategoryDistributionPieChart"] = "ProductCategoryDistributionPieChart"\n    size: WidgetSize = "medium"\n\n    # Parameters\n    metric: Metric\n    textinfo: Literal["percent", "value"] = "percent"\n    sort_order: Literal["asc", "desc"] = "desc"  # top or bottom products\n    limit: int = 5\n\n    # Filters\n    period: Optional[Period]\n    filters: db.Filters = db.Filters()\n\n    @staticmethod\n    def description() -> str:\n        return "Purchase Behaviour - Product"\n\n    @staticmethod\n    def example_figure() -> go.Figure:\n        return example_pie_chart()\n\n    def default_title(self) -> str:\n        return f"Purchase Behavior - {SORT_LABELS[self.sort_order]} Product"\n\n    def edit_parameters(self) -> None:\n        title = st.text_input("Title", value=self.title, placeholder=self.default_title())\n        textinfo = st.radio(\n            "Viewing mode",\n            VIEWING_MODES,\n            index=VIEWING_MODES.index(self.textinfo),\n            horizontal=True,\n            format_func=str.capitalize,\n        )\n\n        sort_order = st.radio(\n            "Bestselling or Underperforming",\n            ["desc", "asc"],\n            index=["desc", "asc"].index(self.sort_order),\n            horizontal=True,\n            format_func=lambda value: SORT_LABELS[value],\n        )\n\n        limit = st.number_input(f"Count", value=self.limit)\n\n        st.markdown("#### Filters")\n        start_year, end_year = year_range_slider(self.metric, self.period)\n        filters = multiselect_dimension_filters(self.metric, self.filters)\n\n        def apply_changes() -> None:\n            self.title = title\n            self.textinfo = textinfo\n            self.limit = limit\n            self.sort_order = sort_order\n            self.period = Period(start=date(start_year, 1, 1), end=date(end_year, 12, 31))\n            self.filters = filters\n\n        st.button("Apply", use_container_width=True, on_click=apply_changes)\n\n    def figure(self) -> go.Figure:\n        df = fetch_categories(self.metric, self.filters, self.period, limit=self.limit, sort_order=self.sort_order)\n\n        return (\n            go.Figure(\n                layout=go.Layout(title=self.displayed_title()),\n                data=go.Pie(\n                    labels=df[self.metric.columns.category],\n                    values=df[self.metric.columns.metric_column],\n                    textinfo=self.textinfo,\n                ).update(PIE_STYLE),\n            )\n            .update_layout(PLOT_LAYOUT)\n            .update_layout(PIE_LAYOUT)\n        )\n\n\nclass ProductCategoriesComparisonBarGraph(Widget):\n    widget_kind: Literal["chart", "kpi", "text"] = "chart"\n    widget_type: Literal["ProductCategoriesComparisonBarGraph"] = "ProductCategoriesComparisonBarGraph"\n    size: WidgetSize = "medium"\n\n    # Parameters\n    metric: Metric\n    year_a: Optional[int]\n    year_b: Optional[int]\n\n    # Filters\n    filters: db.Filters = db.Filters()\n\n    @staticmethod\n    def description() -> str:\n        return "Bar Graph of Top Product Categories"\n\n    @staticmethod\n    def example_figure() -> go.Figure:\n        return example_bar_comparison_chart()\n\n    def default_title(self) -> str:\n        return "Product Category YoY"\n\n    def edit_parameters(self) -> None:\n        title = st.text_input("Title", value=self.title, placeholder=self.default_title())\n\n        min_date, max_date = self.metric.date_range()\n        years = list(range(min_date.year, max_date.year + 1))\n\n        cols = st.columns([1, 1])\n        year_a = cols[0].selectbox("Comparing year", years, index=years.index(self.year_a or max_date.year - 1))\n        year_b = cols[1].selectbox("with year", years, index=years.index(self.year_b or max_date.year))\n\n        st.markdown("#### Filters")\n        filters = multiselect_dimension_filters(self.metric, self.filters)\n\n        def apply_changes() -> None:\n            self.title = title\n            self.year_a = year_a\n            self.year_b = year_b\n            self.filters = filters\n\n        st.button("Apply", use_container_width=True, on_click=apply_changes)\n\n    def figure(self) -> go.Figure:\n        _, max_date = self.metric.date_range()\n        df_a = fetch_categories(self.metric, self.filters, Period.from_year(self.year_a or max_date.year - 1))\n        df_b = fetch_categories(self.metric, self.filters, Period.from_year(self.year_b or max_date.year))\n\n        cols = self.metric.columns\n        return go.Figure(\n            layout=go.Layout(title=self.displayed_title()),\n            data=[\n                go.Bar(\n                    name=self.year_a or max_date.year - 1,\n                    x=df_a[cols.category],\n                    y=df_a[cols.metric_column],\n                    marker_color=COLORS["bar-chart-a"],\n                ).update(BAR_STYLE),\n                go.Bar(\n                    name=self.year_b or max_date.year,\n                    x=df_b[cols.category],\n                    y=df_b[cols.metric_column],\n                    marker_color=COLORS["bar-chart-b"],\n                ).update(BAR_STYLE),\n            ],\n        ).update_layout(PLOT_LAYOUT)\n\n\n@st.cache_data\ndef fetch_categories(\n    metric: Metric,\n    filters: db.Filters,\n    period: Optional[Period] = None,\n    limit: int = 100,\n    sort_order: SortOrder = "desc",\n) -> pd.DataFrame:\n    cols = metric.columns\n    return (\n        metric.dataframe()\n        .filter(filters.to_condition())\n        .filter(f.col(cols.timestamp).between(period.start, period.end) if period else f.lit(True))\n        .group_by(cols.category)\n        .agg(f.sum(cols.metric_column).alias(cols.metric_column))\n        .sort(cols.metric_column, ascending=sort_order == "asc")\n        .limit(limit)\n        .to_pandas()\n    )\n\n\ndef retrieve_category_column(metric: Metric) -> str:\n    assert len(metric.columns.dimensions) > 0, "Metric must have a category column."\n\n    CATEGORY_WORDS = ["CATEGORY", "KIND", "TYPE", "CAT"]\n\n    for word in CATEGORY_WORDS:\n        for col in metric.columns.dimensions:\n            if word in col.upper():\n                return col\n\n    return metric.columns.dimensions[0]\n')
    __stickytape_write_module('widgets/purchasing_trend_over_time_widgets.py', b'from datetime import date\nfrom typing import Literal, Optional\n\nimport pandas as pd\nimport plotly.graph_objs as go\nimport snowflake.snowpark.functions as f\nimport streamlit as st\nfrom typing_extensions import Literal\n\nfrom data.metric import Metric\nfrom range_analysis_app import db\nfrom range_analysis_app.definitions.period import Period\nfrom range_analysis_app.definitions.time_series import GRAINS, Grain, TimeSeries\nfrom range_analysis_app.exploration.plotly_styles import PLOT_LAYOUT, SCATTER_STYLE\nfrom widgets.example_charts import example_line_chart\nfrom widgets.parameters import multiselect_dimension_filters, year_range_slider\nfrom widgets.widget import Widget, WidgetSize\n\n\nclass PurchasingTrendsLineChart(Widget):\n    widget_kind: Literal["chart", "kpi", "text"] = "chart"\n    widget_type: Literal["MonthlyPurchasingTrendsLineChart"] = "MonthlyPurchasingTrendsLineChart"\n    size: WidgetSize = "medium"\n\n    # Parameters\n    metric: Metric\n    grain: Grain = "month"\n\n    # Filters\n    period: Optional[Period]\n    filters: db.Filters = db.Filters()\n\n    @staticmethod\n    def description() -> str:\n        return "Line Chart of Purchasing Trends"\n\n    @staticmethod\n    def example_figure() -> go.Figure:\n        return example_line_chart()\n\n    def default_title(self) -> str:\n        NAMES = {\n            "day": "Daily",\n            "week": "Weekly",\n            "month": "Monthly",\n            "quarter": "Quarterly",\n            "year": "Yearly",\n        }\n        return f"{NAMES[self.grain]} Purchasing Trend"\n\n    def edit_parameters(self) -> None:\n        title = st.text_input("Title", value=self.title, placeholder=self.default_title())\n        grain = st.selectbox("Periodicity", GRAINS, index=GRAINS.index(self.grain))\n\n        st.markdown("#### Filters")\n        start_year, end_year = year_range_slider(self.metric, self.period)\n        filters = multiselect_dimension_filters(self.metric, self.filters)\n\n        def apply_changes() -> None:\n            self.title = title\n            self.grain = grain\n            self.period = Period(start=date(start_year, 1, 1), end=date(end_year, 12, 31))\n            self.filters = filters\n\n        st.button("Apply", use_container_width=True, on_click=apply_changes)\n\n    def figure(self) -> go.Figure:\n        df = fetch_time_series(self.metric, self.grain, self.filters, self.period)\n\n        metric = self.metric\n        metric_column = metric.columns.metric_column.lower()\n\n        return go.Figure(\n            layout=go.Layout(title=self.displayed_title()),\n            data=go.Scatter(\n                name=metric.name,\n                x=df["period"],\n                y=df[metric_column],\n                mode="lines+markers",\n            ).update(SCATTER_STYLE),\n        ).update_layout(PLOT_LAYOUT)\n\n\n@st.cache_data\ndef fetch_time_series(\n    metric: Metric,\n    grain: Grain,\n    filters: db.Filters,\n    period: Optional[Period] = None,\n) -> pd.DataFrame:\n    metric_column = metric.columns.metric_column\n\n    return pd.DataFrame(\n        TimeSeries(metric=metric, grain=grain)\n        .dataframe()\n        .filter(filters.to_condition())\n        .filter(f.col("period").between(period.start, period.end) if period else f.lit(True))\n        .group_by("period")\n        .agg(f.sum(metric_column).alias(metric_column))\n        .sort("period")\n        .collect()\n    ).rename(columns=str.lower)\n')
    __stickytape_write_module('sample_configuration.py', b'import datetime\n\nfrom data import db\n\nsample_data = {"database": db.fetch_current_database(), "schema": "MAXA_DEMO"}\n\nsample_config = {\n    "dimensions": [\n        {"uid": "e9913d67-07b9-43cd-9793-97c8f714928e", "name": "Product", "predefined": True},\n        {"uid": "41798dd3-0d3d-4d2b-ac45-0a9f8b4204c5", "name": "Category", "predefined": False},\n        {"uid": "47b57c81-ae2f-4e97-8fd0-50f592c8fc70", "name": "Customer", "predefined": False},\n    ],\n    "activities": [{"uid": "3c706611-2461-46df-aee4-9aca8687f796", "name": "Purchase Order", "predefined": True}],\n    "metrics": [\n        {\n            "uid": "949a127b-9414-4d36-9b80-4bed90d33e50",\n            "name": "Revenue",\n            "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n            "columns": {\n                "dimensions": ["REGION", "CUSTOMER_NAME", "PRODUCT_NAME"],\n                "metric_column": "PRICE",\n                "timestamp": "PURCHASE_DATE",\n                "agg_method": "sum",\n                "category": "CATEGORY",\n                "labels": {\n                    "PURCHASE_DATE": "Period",\n                    "PRICE": "Revenue",\n                    "CATEGORY": "Product Category",\n                    "REGION": "Region",\n                    "CUSTOMER_NAME": "Customer Name",\n                    "PRODUCT_NAME": "Product Name",\n                },\n            },\n        }\n    ],\n    "selected_tables": [\n        {\n            "uid": "bb9a436e-167a-4b05-9d5d-6b186495c547",\n            "table_name": "PURCHASE_ORDER",\n            "table_schema": sample_data["schema"],\n            "table_database": sample_data["database"],\n            "entity_uid": "3c706611-2461-46df-aee4-9aca8687f796",\n            "entity_type": "activity",\n            "columns": {\n                "ORDER_ID": "INTEGER",\n                "PURCHASE_DATE": "DATE",\n                "PRODUCT_ID": "INTEGER",\n                "QUANTITY": "INTEGER",\n                "PRICE": "INTEGER",\n                "CUSTOMER_ID": "INTEGER",\n                "SUPPLIER_ID": "INTEGER",\n                "STATUS": "TEXT",\n            },\n        },\n        {\n            "uid": "6b563b80-1a35-489f-8c46-2c84d088bfa1",\n            "table_name": "PRODUCT",\n            "table_schema": sample_data["schema"],\n            "table_database": sample_data["database"],\n            "entity_uid": "e9913d67-07b9-43cd-9793-97c8f714928e",\n            "entity_type": "dimension",\n            "columns": {"PRODUCT_ID": "INTEGER", "PRODUCT_NAME": "TEXT", "CATEGORY_ID": "INTEGER", "PRICE": "INTEGER"},\n        },\n        {\n            "uid": "39a13c71-d570-4f18-9164-22a2148bdb04",\n            "table_name": "CATEGORY",\n            "table_schema": sample_data["schema"],\n            "table_database": sample_data["database"],\n            "entity_uid": "41798dd3-0d3d-4d2b-ac45-0a9f8b4204c5",\n            "entity_type": "dimension",\n            "columns": {"CATEGORY_ID": "INTEGER", "CATEGORY": "TEXT"},\n        },\n        {\n            "uid": "810311a4-6894-4693-84bb-e213d6a46577",\n            "table_name": "CUSTOMER",\n            "table_schema": sample_data["schema"],\n            "table_database": sample_data["database"],\n            "entity_uid": "47b57c81-ae2f-4e97-8fd0-50f592c8fc70",\n            "entity_type": "dimension",\n            "columns": {"CUSTOMER_ID": "INTEGER", "CUSTOMER_NAME": "TEXT", "CUSTOMER_PHONE": "TEXT", "REGION": "TEXT"},\n        },\n    ],\n    "dim_act_mappings": [\n        {\n            "dim_id": "e9913d67-07b9-43cd-9793-97c8f714928e",\n            "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n            "main_table_id": "bb9a436e-167a-4b05-9d5d-6b186495c547",\n            "joined_table_id": "6b563b80-1a35-489f-8c46-2c84d088bfa1",\n            "main_column": "PRODUCT_ID",\n            "joined_column": "PRODUCT_ID",\n        },\n        {\n            "dim_id": "41798dd3-0d3d-4d2b-ac45-0a9f8b4204c5",\n            "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n            "main_table_id": "6b563b80-1a35-489f-8c46-2c84d088bfa1",\n            "joined_table_id": "39a13c71-d570-4f18-9164-22a2148bdb04",\n            "main_column": "CATEGORY_ID",\n            "joined_column": "CATEGORY_ID",\n        },\n        {\n            "dim_id": "47b57c81-ae2f-4e97-8fd0-50f592c8fc70",\n            "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n            "main_table_id": "bb9a436e-167a-4b05-9d5d-6b186495c547",\n            "joined_table_id": "810311a4-6894-4693-84bb-e213d6a46577",\n            "main_column": "CUSTOMER_ID",\n            "joined_column": "CUSTOMER_ID",\n        },\n    ],\n    "widgets": [\n        {\n            "widget_kind": "kpi",\n            "size": "small",\n            "title": "",\n            "widget_type": "TotalPurchaseValue",\n            "metric": {\n                "uid": "949a127b-9414-4d36-9b80-4bed90d33e50",\n                "name": "Revenue",\n                "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n                "columns": {\n                    "dimensions": ["REGION", "CUSTOMER_NAME", "PRODUCT_NAME"],\n                    "metric_column": "PRICE",\n                    "timestamp": "PURCHASE_DATE",\n                    "agg_method": "sum",\n                    "category": "CATEGORY",\n                    "labels": {\n                        "PURCHASE_DATE": "Period",\n                        "PRICE": "Revenue",\n                        "CATEGORY": "Product Category",\n                        "REGION": "Region",\n                        "CUSTOMER_NAME": "Customer Name",\n                        "PRODUCT_NAME": "Product Name",\n                    },\n                },\n            },\n            "grain": "year",\n            "period": None,\n            "filters": {"mapping": {}},\n        },\n        {\n            "widget_kind": "kpi",\n            "size": "small",\n            "title": "",\n            "widget_type": "TotalPurchaseValue",\n            "metric": {\n                "uid": "949a127b-9414-4d36-9b80-4bed90d33e50",\n                "name": "Revenue",\n                "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n                "columns": {\n                    "dimensions": ["REGION", "CUSTOMER_NAME", "PRODUCT_NAME"],\n                    "metric_column": "PRICE",\n                    "timestamp": "PURCHASE_DATE",\n                    "agg_method": "sum",\n                    "category": "CATEGORY",\n                    "labels": {\n                        "PURCHASE_DATE": "Period",\n                        "PRICE": "Revenue",\n                        "CATEGORY": "Product Category",\n                        "REGION": "Region",\n                        "CUSTOMER_NAME": "Customer Name",\n                        "PRODUCT_NAME": "Product Name",\n                    },\n                },\n            },\n            "grain": "month",\n            "period": None,\n            "filters": {"mapping": {}},\n        },\n        {\n            "widget_kind": "kpi",\n            "size": "small",\n            "title": "",\n            "widget_type": "TotalPurchaseValue",\n            "metric": {\n                "uid": "949a127b-9414-4d36-9b80-4bed90d33e50",\n                "name": "Revenue",\n                "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n                "columns": {\n                    "dimensions": ["REGION", "CUSTOMER_NAME", "PRODUCT_NAME"],\n                    "metric_column": "PRICE",\n                    "timestamp": "PURCHASE_DATE",\n                    "agg_method": "sum",\n                    "category": "CATEGORY",\n                    "labels": {\n                        "PURCHASE_DATE": "Period",\n                        "PRICE": "Revenue",\n                        "CATEGORY": "Product Category",\n                        "REGION": "Region",\n                        "CUSTOMER_NAME": "Customer Name",\n                        "PRODUCT_NAME": "Product Name",\n                    },\n                },\n            },\n            "grain": "week",\n            "period": None,\n            "filters": {"mapping": {}},\n        },\n        {\n            "widget_kind": "kpi",\n            "size": "small",\n            "title": "",\n            "widget_type": "TotalPurchaseValue",\n            "metric": {\n                "uid": "949a127b-9414-4d36-9b80-4bed90d33e50",\n                "name": "Revenue",\n                "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n                "columns": {\n                    "dimensions": ["REGION", "CUSTOMER_NAME", "PRODUCT_NAME"],\n                    "metric_column": "PRICE",\n                    "timestamp": "PURCHASE_DATE",\n                    "agg_method": "sum",\n                    "category": "CATEGORY",\n                    "labels": {\n                        "PURCHASE_DATE": "Period",\n                        "PRICE": "Revenue",\n                        "CATEGORY": "Product Category",\n                        "REGION": "Region",\n                        "CUSTOMER_NAME": "Customer Name",\n                        "PRODUCT_NAME": "Product Name",\n                    },\n                },\n            },\n            "grain": "day",\n            "period": None,\n            "filters": {"mapping": {}},\n        },\n        {\n            "widget_kind": "chart",\n            "size": "medium",\n            "title": "",\n            "widget_type": "MonthlyPurchasingTrendsLineChart",\n            "metric": {\n                "uid": "949a127b-9414-4d36-9b80-4bed90d33e50",\n                "name": "Revenue",\n                "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n                "columns": {\n                    "dimensions": ["REGION", "CUSTOMER_NAME", "PRODUCT_NAME"],\n                    "metric_column": "PRICE",\n                    "timestamp": "PURCHASE_DATE",\n                    "agg_method": "sum",\n                    "category": "CATEGORY",\n                    "labels": {\n                        "PURCHASE_DATE": "Period",\n                        "PRICE": "Revenue",\n                        "CATEGORY": "Product Category",\n                        "REGION": "Region",\n                        "CUSTOMER_NAME": "Customer Name",\n                        "PRODUCT_NAME": "Product Name",\n                    },\n                },\n            },\n            "grain": "month",\n            "period": None,\n            "filters": {"mapping": {}},\n        },\n        {\n            "widget_kind": "chart",\n            "size": "medium",\n            "title": "",\n            "widget_type": "ProductCategoriesComparisonBarGraph",\n            "metric": {\n                "uid": "949a127b-9414-4d36-9b80-4bed90d33e50",\n                "name": "Revenue",\n                "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n                "columns": {\n                    "dimensions": ["REGION", "CUSTOMER_NAME", "PRODUCT_NAME"],\n                    "metric_column": "PRICE",\n                    "timestamp": "PURCHASE_DATE",\n                    "agg_method": "sum",\n                    "category": "CATEGORY",\n                    "labels": {\n                        "PURCHASE_DATE": "Period",\n                        "PRICE": "Revenue",\n                        "CATEGORY": "Product Category",\n                        "REGION": "Region",\n                        "CUSTOMER_NAME": "Customer Name",\n                        "PRODUCT_NAME": "Product Name",\n                    },\n                },\n            },\n            "year_a": None,\n            "year_b": None,\n            "filters": {"mapping": {}},\n        },\n        {\n            "widget_kind": "chart",\n            "size": "medium",\n            "title": "",\n            "widget_type": "ProductCategoryDistributionPieChart",\n            "metric": {\n                "uid": "949a127b-9414-4d36-9b80-4bed90d33e50",\n                "name": "Revenue",\n                "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n                "columns": {\n                    "dimensions": ["REGION", "CUSTOMER_NAME", "PRODUCT_NAME"],\n                    "metric_column": "PRICE",\n                    "timestamp": "PURCHASE_DATE",\n                    "agg_method": "sum",\n                    "category": "CATEGORY",\n                    "labels": {\n                        "PURCHASE_DATE": "Period",\n                        "PRICE": "Revenue",\n                        "CATEGORY": "Product Category",\n                        "REGION": "Region",\n                        "CUSTOMER_NAME": "Customer Name",\n                        "PRODUCT_NAME": "Product Name",\n                    },\n                },\n            },\n            "textinfo": "percent",\n            "sort_order": "desc",\n            "limit": 5,\n            "period": None,\n            "filters": {"mapping": {}},\n        },\n        {\n            "widget_kind": "chart",\n            "size": "large",\n            "title": "",\n            "widget_type": "PurchaseAnomaliesHeatmap",\n            "metric": {\n                "uid": "949a127b-9414-4d36-9b80-4bed90d33e50",\n                "name": "Revenue",\n                "act_id": "3c706611-2461-46df-aee4-9aca8687f796",\n                "columns": {\n                    "dimensions": ["REGION", "CUSTOMER_NAME", "PRODUCT_NAME"],\n                    "metric_column": "PRICE",\n                    "timestamp": "PURCHASE_DATE",\n                    "agg_method": "sum",\n                    "category": "CATEGORY",\n                    "labels": {\n                        "PURCHASE_DATE": "Period",\n                        "PRICE": "Revenue",\n                        "CATEGORY": "Product Category",\n                        "REGION": "Region",\n                        "CUSTOMER_NAME": "Customer Name",\n                        "PRODUCT_NAME": "Product Name",\n                    },\n                },\n            },\n            "x_col": "day_of_week",\n            "period": {"start": datetime.date(2019, 1, 1), "end": datetime.date(2023, 12, 31)},\n            "filters": {"mapping": {}},\n        },\n    ],\n}\n')
    __stickytape_write_module('data/db.py', b'from typing import List\n\nimport streamlit as st\n\nfrom range_analysis_app.db import snowflake_session\n\n\n@st.cache_data\ndef fetch_databases() -> List[str]:\n    for _attempt in range(3):\n        rows = snowflake_session().sql(f"show databases").collect()\n        if len(rows) > 0:\n            return [row.name for row in snowflake_session().sql(f"show databases").collect()]\n\n    raise ValueError("No database available.")\n\n\n@st.cache_data\ndef fetch_current_database() -> str:\n    row = snowflake_session().sql(f"select current_database() as current_database").first()\n    return row.CURRENT_DATABASE\n\n\n@st.cache_data\ndef fetch_schemas(database: str = "") -> List[str]:\n    return [row.name for row in snowflake_session().sql(f"show schemas in database {database}").collect()]\n\n\n@st.cache_data\ndef fetch_tables(database: str, schema: str) -> List[str]:\n    tables = snowflake_session().sql(f"show tables in schema {database}.{schema}").collect()\n    views = snowflake_session().sql(f"show views in schema {database}.{schema}").collect()\n    return [row.name for row in tables + views]\n')
    __stickytape_write_module('widgets/widget_gallery.py', b'from typing import Callable, List, Type\n\nimport streamlit as st\n\nfrom range_analysis_app.exploration.plotly_styles import PLOTLY_CONFIG\nfrom widgets.kpis import TotalPurchaseValue\nfrom widgets.outlier_detection_widgets import PurchaseAnomaliesHeatmap\nfrom widgets.product_category_distribution_widgets import (\n    ProductCategoriesComparisonBarGraph,\n    ProductCategoryDistributionPieChart,\n)\nfrom widgets.purchasing_trend_over_time_widgets import PurchasingTrendsLineChart\nfrom widgets.widget import Widget\n\n\ndef widget_gallery(on_add: Callable[[Type[Widget]], None]) -> None:\n    """Gallery of widgets to display in the sidebar."""\n    render_widget_category(\n        title="Product Category Distribution",\n        widget_classes=[ProductCategoryDistributionPieChart],\n        on_add=on_add,\n    )\n    render_widget_category(\n        title="Purchasing Trends Over Time",\n        widget_classes=[PurchasingTrendsLineChart, ProductCategoriesComparisonBarGraph],\n        on_add=on_add,\n    )\n    render_widget_category(\n        title="Outlier Detection",\n        widget_classes=[PurchaseAnomaliesHeatmap],\n        on_add=on_add,\n    )\n    render_widget_category(\n        title="KPIs",\n        widget_classes=[TotalPurchaseValue],\n        on_add=on_add,\n    )\n\n\ndef render_widget_category(\n    title: str,\n    widget_classes: List[Type[Widget]],\n    on_add: Callable[[Type[Widget]], None],\n):\n    if len(widget_classes) == 0:\n        return\n\n    st.markdown(f"## {title}")\n\n    for widget_class in widget_classes:\n        st.markdown(f"**{widget_class.description()}**")\n        cols = st.columns([1, 22, 1])\n        cols[1].plotly_chart(widget_class.example_figure(), config=PLOTLY_CONFIG, use_container_width=True)\n\n        def add_widget(widget_class: Type[Widget]):\n            return lambda: on_add(widget_class)\n\n        st.button(\n            "\\+ Add widget",\n            key=f"add-{widget_class.__name__}",\n            use_container_width=True,\n            on_click=add_widget(widget_class),\n        )\n')
    __stickytape_write_module('app_pages/help_page.py', b'from typing import Dict, Type\n\nimport streamlit as st\n\nfrom app_pages.data_loading import DataLoadingPage\nfrom app_pages.doma_entities_page import DomaEntitiesPage\nfrom app_pages.mapping import MappingPage\nfrom app_pages.metrics_creation import MetricsCreationPage\nfrom app_pages.page import Page\nfrom app_pages.summary_settings_page import SummarySettingsPage\n\n\nclass HelpPage(Page):\n    @property\n    def page_description(self) -> str:\n        return "Help"\n\n    def run(self) -> None:\n        st.markdown(\n            """\n            ##### This app helps you to:\n\n            - Gain valuable insights into purchasing behavior and detect outliers effortlessly.\n            - Visualize distribution of buying behavior for all or specific products.\n            - Empower financial managers to optimize strategies, drive cost and operational efficiency improvements, and enhance margins.\n\n            ##### Modes\n\n            1. **Demo Mode** (default): Maxa comes preloaded with a dataset and pre-generated widgets for immediate data exploration and analysis.  \n               Dive into the **Dashboard** tab to visualize the dataset and experience Maxa\'s capabilities. Ideal for quick analysis and familiarizing yourself with the platform.\n            2. **Custom Mode**: Map your own tables for a personalized analysis environment and gain deeper insights on your data. \n\n            Switching between modes:\n\n            - Go to the **Configuration** tab to map your own tables or reset to the **Demo Mode**.\n\n            ##### Workflow\n\n            - Map your data to create a personalized analysis environment or use the preloaded Maxa dataset.\n            - Navigate to the **Dashboard** tab to start visualizing and analyzing your data.\n            - Customize and configure widgets to display relevant information for your analysis.\n                - By default, the timeframe selected will be the last period seen on the dataset \n            - Gain insights into purchasing behavior, detect outliers, and optimize strategies.\n            - Repeat the process to update or switch datasets as needed for ongoing analysis.\n            """\n        )\n')
    __stickytape_write_module('app_pages/data_loading.py', b'from typing import Dict, List, Optional, Tuple\n\nimport streamlit as st\n\nfrom app_pages.mapping import MappingPage\nfrom app_pages.page import Page\nfrom data.db import fetch_current_database, fetch_databases, fetch_schemas, fetch_tables\nfrom data.helpers import repository\nfrom data.models import DbTable, Dimension, Entity\nfrom range_analysis_app import db\n\nPREDEFINED_DIMS = ["Purchase Order", "Product", "Category", "Customer", "Supplier", "Country", "Orders"]\n\nOBSERVED_FIELDS = {"dimensions", "activities", "selected_tables"}\n\n\nclass DataLoadingPage(Page):\n    @property\n    def page_description(self) -> str:\n        return "This page allows users to select the tables and map they to DOMA entities"\n\n    def run(self) -> None:\n        entities: List[Entity] = repository().activities + repository().dimensions\n\n        left, right = st.columns([6, 6])\n        with left:\n            selected_database, selected_schema, tables = self.select_data_source()\n            with st.expander("How to add your database ?"):\n                current_app_name = fetch_current_database()\n\n                st.markdown(\n                    f"""\n                    To add your database, you must grant access to it to the application. For example:\n\n                    ```sql\n                    grant usage on database "SNOWFLAKE_SAMPLE_DATA" to application "{current_app_name}";\n                    grant usage on schema "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1" to application "{current_app_name}";\n                    grant select on all tables in schema "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1" to application "{current_app_name}";\n                    grant select on all views in schema "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1" to application "{current_app_name}";\n                    ```\n\n                    Then refresh the databases:\n                    """\n                )\n                st.button("Refresh databases", on_click=fetch_databases.clear)\n        with right:\n            self.mapping(entities, selected_database, selected_schema, tables)\n\n    def mapping(\n        self,\n        entities: List[Entity],\n        selected_database: str,\n        selected_schema: str,\n        tables: List[str],\n    ):\n        remaining_dims = [dim for dim in PREDEFINED_DIMS if dim not in (entity.name for entity in entities)]\n\n        cols = st.columns([5, 5, 2])\n        cols[0].markdown("**Define dimensions**")\n        cols[1].markdown("**Associate table source**")\n\n        for idx, entity in enumerate(entities):\n            self.mapping_row(entity, idx, selected_database, selected_schema, tables, remaining_dims)\n\n        cols = st.columns([5, 5, 2])\n\n        if remaining_dims:\n\n            def create_dimension():\n                dim = Dimension.create(name=remaining_dims[0])\n                repository().activities[0].assign_dimension(dim.uid)\n\n            cols[0].button("\\+ Add dimension", use_container_width=True, on_click=create_dimension)\n\n    def select_data_source(self) -> Tuple[str, str, List[str]]:\n        """Return the (database, schema, tables) of the selected data source."""\n        existing_table = repository().selected_tables[0] if repository().selected_tables else None\n\n        left, right = st.columns([6, 6])\n        with left:\n            st.markdown("**Database**")\n\n            databases = fetch_databases()\n            default_database_index = databases.index(existing_table.table_database) if existing_table else 0\n\n            selected_database = left.selectbox(\n                "Database",\n                key="selected_database",\n                options=databases,\n                index=default_database_index,\n                label_visibility="collapsed",\n            )\n\n        with right:\n            st.markdown("**Schema**")\n\n            schemas = fetch_schemas(selected_database)\n            default_schema_index = (\n                schemas.index(existing_table.table_schema)\n                if existing_table and existing_table.table_database == selected_database\n                else 0\n            )\n\n            selected_schema = st.selectbox(\n                "Schema",\n                key="selected_schema",\n                options=schemas,\n                index=default_schema_index,\n                label_visibility="collapsed",\n            )\n\n        tables = fetch_tables(selected_database, selected_schema)\n\n        return selected_database, selected_schema, tables\n\n    def mapping_row(\n        self,\n        entity: Entity,\n        idx: int,\n        selected_database: str,\n        selected_schema: str,\n        tables: List[str],\n        remaining_dims: List[str],\n    ):\n        table = self._find_table(entity)\n\n        selected_table_idx = None\n        if table is None:\n            selected_table_idx = 0\n        elif table.table_schema == selected_schema and table.table_database == selected_database:\n            selected_table_idx = tables.index(table.table_name) + 1\n\n        cols = st.columns([5, 5, 2])\n\n        def update_entity_name():\n            entity.name = st.session_state[f"entity-name-{idx}"]\n\n        if entity.predefined:\n            cols[0].text_input(\n                "Entity name",\n                value=entity.name,\n                disabled=True,\n                label_visibility="collapsed",\n            )\n        else:\n            cols[0].selectbox(\n                "Entity name",\n                [entity.name] + remaining_dims,\n                label_visibility="collapsed",\n                key=f"entity-name-{idx}",\n                on_change=update_entity_name,\n            )\n\n        key = f"tbl_{idx}"\n        DEFAULT = "Select table..."\n\n        if selected_table_idx is not None:\n            if not tables:\n                cols[1].text_input(\n                    "Source table",\n                    value="No table to associate...",\n                    key=key,\n                    disabled=True,\n                    label_visibility="collapsed",\n                )\n                return\n\n            def update_selected_table():\n                self._remove_table(entity)\n\n                selected_table_name = st.session_state[key]\n                if selected_table_name == DEFAULT:\n                    return\n\n                full_selected_table = f"{selected_database}.{selected_schema}.{selected_table_name}"\n\n                columns = db.fetch_columns(full_selected_table)\n                DbTable.create(\n                    table_database=selected_database,\n                    table_schema=selected_schema,\n                    table_name=selected_table_name,\n                    columns=columns,\n                    entity=entity,\n                )\n\n            cols[1].selectbox(\n                "Source table",\n                key=key,\n                options=["Select table..."] + tables,\n                index=selected_table_idx,\n                label_visibility="collapsed",\n                on_change=update_selected_table,\n            )\n            if not entity.predefined:\n                cols[2].button("\xe2\x9c\x95", key=f"remove_{key}", on_click=entity.delete)\n\n        else:\n            cols[1].text_input(\n                "Source table",\n                value=remove_prefix(table.full_name, f"{selected_database}."),\n                key=key,\n                disabled=True,\n                label_visibility="collapsed",\n            )\n            cols[2].button("\xe2\x9c\x8e", key=f"edit_{key}", on_click=lambda: self._remove_table(entity))\n\n    def _find_table(self, entity: Entity) -> Optional[DbTable]:\n        for tbl in repository().selected_tables:\n            if entity.uid == tbl.entity_uid:\n                return tbl\n\n        return None\n\n    def _remove_table(self, entity: Entity):\n        table = self._find_table(entity)\n        if table is None:\n            return\n        table.delete()\n\n\ndef remove_prefix(text: str, prefix: str) -> str:\n    """Remove the given prefix from the text."""\n    if text.startswith(prefix):\n        return text[len(prefix) :]\n    return text\n')
    __stickytape_write_module('app_pages/mapping.py', b'from typing import List\n\nimport streamlit as st\nfrom streamlit.runtime.state import WidgetCallback\n\nfrom app_pages.page import Page\nfrom data.helpers import render_validation_component, repository, validate_state\nfrom data.models import Activity, DbTable, DimensionActivityMapping\nfrom data.repository import Repository\nfrom diagrams.mapping_diagram import graphviz_table_relations\nfrom range_analysis_app.db import ID_TYPES\nfrom streamlit_in_snowflake import st_image_base64\n\nNONE_SELECT = "Select column..."\n\n\nclass MappingPage(Page):\n    @property\n    def page_description(self) -> str:\n        return "This page provides an allows to configure relations between Activities and Dimensions"\n\n    def run(self) -> None:\n        if not self.is_valid():\n            return\n\n        for act_idx, activity in enumerate(repository().activities):\n            if act_idx != 0:\n                st.markdown("---")\n\n            self.render_activity(activity)\n\n    @staticmethod\n    def reset_edition_state() -> None:\n        st.session_state["mapping_repo_in_edition"] = repository().copy()\n\n    @staticmethod\n    def is_valid() -> bool:\n        dimensions_valid, _ = validate_state(repository().dimensions, "dimension", validate_each=True)\n        activities_valid, _ = validate_state(repository().activities, "activity", validate_each=True)\n\n        if not dimensions_valid or not activities_valid:\n            st.warning("Missing mapping in **:blue[Step 1]**.")\n            return False\n\n        return True\n\n    def render_activity(self, activity: Activity) -> None:\n        activity_table = activity.db_table\n        assert activity_table, "Activity is validated to have a table"\n\n        dimension_tables: List[DbTable] = [dim.db_table for dim in activity.dimensions]\n        assert all(dimension_tables), "Dimensions are validated to have tables"\n\n        if len(activity.mappings) == 0:\n            st.markdown("No dimension to associate.")\n            return\n\n        for index, mapping in enumerate(activity.mappings):\n            self.render_mapping(mapping, dimension_tables, is_first=index == 0)\n\n        st.markdown("###")\n        graphviz_table_relations(activity)\n\n    def render_mapping(\n        self,\n        mapping: DimensionActivityMapping,\n        dimension_tables: List[DbTable],\n        is_first: bool,\n    ) -> None:\n        activity = mapping.activity\n        dimension = mapping.dimension\n\n        activity_table = activity.db_table\n        mapping_key = f"{activity.uid}_{dimension.uid}"\n\n        current_dim_table = dimension.db_table\n\n        cols = st.columns([3, 3, 1, 3, 3])\n\n        # Default mapping\n        if mapping.main_table is None or mapping.joined_table is None:\n            mapping.main_table_id = activity_table.uid\n            mapping.joined_table_id = current_dim_table.uid\n            mapping.main_column = None  # Column to actively set\n            mapping.joined_column = current_dim_table.columns_of_type(ID_TYPES)[0]\n\n        def set_mapping_field(field: str, state_key: str) -> WidgetCallback:\n            def set_value():\n                value = st.session_state[state_key]\n                if value == NONE_SELECT:\n                    value = None\n\n                setattr(mapping, field, st.session_state[state_key])\n\n            return set_value\n\n        with cols[0]:\n            st.text_input(\n                "**Dimension table**",\n                value=mapping.joined_table.table_name,\n                key=f"dimension_{mapping_key}",\n                disabled=True,\n                label_visibility="visible" if is_first else "collapsed",\n            )\n\n        with cols[1]:\n            joined_table = current_dim_table\n            joined_columns = joined_table.columns_of_type(ID_TYPES)\n\n            st.selectbox(\n                "**Column**",\n                options=joined_columns,\n                index=joined_columns.index(mapping.joined_column),\n                key=f"joined_column_{mapping_key}",\n                on_change=set_mapping_field("joined_column", f"joined_column_{mapping_key}"),\n                label_visibility="visible" if is_first else "collapsed",\n            )\n\n        with cols[2]:\n            if is_first:\n                st.markdown("##")\n            st_image_base64("arrow.png")\n\n        with cols[3]:\n            other_dim_tables = [dim_table for dim_table in dimension_tables if dim_table != current_dim_table]\n\n            def update_main_table() -> None:\n                selected_table: DbTable = st.session_state[f"main_table_{mapping_key}"]\n                mapping.main_table_id = selected_table.uid\n                mapping.main_column = selected_table.columns_of_type(ID_TYPES)[0]\n\n            tables = [activity_table] + other_dim_tables\n\n            st.selectbox(\n                "**Associated with table**",\n                options=tables,\n                index=tables.index(mapping.main_table),\n                format_func=lambda table: table.table_name,\n                key=f"main_table_{mapping_key}",\n                on_change=update_main_table,\n                label_visibility="visible" if is_first else "collapsed",\n            )\n\n        with cols[4]:\n            main_table = mapping.main_table\n            main_columns = main_table.columns_of_type(ID_TYPES)\n\n            st.selectbox(\n                "**Target Column**",\n                options=[NONE_SELECT] + main_columns,\n                index=main_columns.index(mapping.main_column) + 1 if mapping.main_column else 0,\n                key=f"main_column_{mapping_key}",\n                on_change=set_mapping_field("main_column", f"main_column_{mapping_key}"),\n                label_visibility="visible" if is_first else "collapsed",\n            )\n')
    __stickytape_write_module('diagrams/__init__.py', b'')
    __stickytape_write_module('diagrams/mapping_diagram.py', b'import streamlit as st\n\nfrom data.models import Activity, DbTable, DimensionActivityMapping\nfrom diagrams.entity_diagram import ENTITY_COLORS\n\n\ndef graphviz_table_relations(activity: Activity) -> None:\n    """Entity-Relationship-Diagram between Activity and Dimension tables."""\n    act_table = activity.db_table\n    tables = [act_table] + [dim.db_table for dim in activity.dimensions]\n\n    table_nodes = "\\n".join(_graphviz_table_node(table) for table in tables)\n    table_edges = "\\n".join(_graphviz_edge(mapping) for mapping in activity.mappings)\n\n    graphviz_dot = f"""\n        digraph G {{\n            graph [fontname="Source Sans Pro", fontsize=20, layout=dot, rankdir=LR, newrank=true]\n            node [style=filled, shape=rect, shape=plaintext]\n            edge [arrowsize=0.75]\n\n            {table_nodes}\n            {table_edges}\n        }}\n    """\n\n    st.graphviz_chart(graphviz_dot, use_container_width=True)\n\n\ndef _graphviz_table_node(table: DbTable) -> str:\n    """Return a html table representing the table and its columns."""\n    col_table_rows = "\\n".join(f"""<tr><td port="{col}">{col}</td></tr>""" for col, _ in table.columns.items())\n    bgcolor = ENTITY_COLORS[table.entity_type]\n\n    label_table = f"""\n        <table border="0" cellborder="1" cellspacing="0">\n            <tr><td bgcolor="{bgcolor}" align="CENTER"><b>{table.table_name}</b></td></tr>\n            {col_table_rows}\n        </table>\n    """\n    return f"""{table.table_name} [fillcolor="#ffffff00" label=<{label_table}>];"""\n\n\ndef _graphviz_edge(mapping: DimensionActivityMapping) -> str:\n    """Return the edge between tables of the mapping."""\n    main_table = mapping.main_table.table_name\n    joined_table = mapping.joined_table.table_name\n\n    return f"{joined_table}:{mapping.joined_column} -> {main_table}:{mapping.main_column}"\n')
    __stickytape_write_module('diagrams/entity_diagram.py', b'from typing import Dict, List, Union\n\nimport streamlit as st\n\nfrom data.helpers import repository\nfrom data.metric import Metric\nfrom data.models import Activity, DbTable, Dimension, DimensionActivityMapping\n\nENTITY_COLORS = {"activity": "#aab3fb", "dimension": "#7cbbf5", "metric": "#1a72c0"}\n\n\ndef entity_color(entity: Union[Activity, Dimension, Metric]) -> str:\n    return ENTITY_COLORS[type(entity).__name__.lower()]\n\n\ndef graphviz_entities() -> None:\n    """Diagram showing relationships between Dimensions Activities and Metrics."""\n    repo = repository()\n\n    nodes = []\n    nodes.extend(f\'"{dimension.name}" [fillcolor="{entity_color(dimension)}"]\' for dimension in repo.dimensions)\n    nodes.extend(f\'"{activity.name}" [fillcolor="{entity_color(activity)}"]\' for activity in repo.activities)\n    nodes.extend(f\'"{metric.name}" [fillcolor="{entity_color(metric)}"]\' for metric in repo.metrics)\n    nodes = "\\n".join(nodes)\n\n    edges = []\n    for activity in repo.activities:\n        edges.extend(f\'"{dim.name}" -> "{activity.name}"\' for dim in activity.dimensions)\n        edges.extend(f\'"{activity.name}" -> "{metric.name}"\' for metric in activity.metrics)\n    edges = "\\n".join(edges)\n\n    graphviz_dot = f"""\n        digraph G {{\n            graph [fontname="Source Sans Pro", fontsize=20, layout=dot, newrank=true]\n            node [style="rounded,filled", shape=box]\n            edge [arrowsize=0.75]\n\n            {nodes}\n            {edges}\n        }}\n    """\n\n    st.graphviz_chart(graphviz_dot)\n')
    __stickytape_write_module('streamlit_in_snowflake.py', b'import base64\nfrom pathlib import Path\n\nimport streamlit as st\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.exceptions import SnowparkSessionException\n\n\n@st.cache_resource\ndef is_inside_snowflake() -> bool:\n    """Return true if Streamlit is executed within Snowflake."""\n    try:\n        _ = get_active_session()\n        return True\n    except SnowparkSessionException:\n        return False\n\n\ndef st_image_base64(image_file: str, folder: Path = Path("images"), **kwargs):\n    """Streamlit image using base64 that can be displayed within Snowflake."""\n    if is_inside_snowflake():\n        folder = Path(".")\n\n    content_bytes = (folder / image_file).read_bytes()\n\n    mime_type = image_file.split(".")[-1:][0].lower()\n    st.image(f"data:image/{mime_type};base64,{base64.b64encode(content_bytes).decode()}", **kwargs)\n\n\ndef snowflake_ui_styles():\n    """Replicate the CSS styles when Streamlit is executed within Snowflake."""\n    if is_inside_snowflake():\n        return\n\n    st.markdown(\n        """\n        <style>\n        \n        /* Hide "Made by Streamlit" */\n        .appview-container .main footer {\n            display: none;\n        }\n        \n        /* Hide background of the top header bar */\n        .stApp > header, .stApp > header > div[data-testid="stDecoration"] {\n            background: #ffffff00;\n        }\n\n        /* Reduce top padding */\n        .main > .block-container {\n            padding-top: 1rem;  /* default = 6rem */\n        }\n        \n        </style>\n        """,\n        unsafe_allow_html=True,\n    )\n')
    __stickytape_write_module('app_pages/doma_entities_page.py', b'from typing import Callable, List\n\nimport streamlit as st\nfrom streamlit.delta_generator import DeltaGenerator\nfrom streamlit.runtime.state import WidgetCallback\n\nfrom app_pages.page import Page\nfrom data.helpers import repository\nfrom data.metric import Metric\nfrom data.models import Activity, Dimension, Entity, EntityType, Id\nfrom diagrams.entity_diagram import graphviz_entities\n\n\ndef render_dimensions(i: int, item: Dimension, item_type: EntityType) -> DeltaGenerator:\n    col1, col2, col3 = st.columns([10, 1, 1])\n    with col1:\n        name_value = item.name\n        name_key = f"[{item_type}][{i}][name]"\n\n        def get_handler(dim: Dimension, key: str) -> WidgetCallback:\n            def h() -> None:\n                dim.name = st.session_state[key]\n\n            return h\n\n        st.text_input(\n            name_key,\n            label_visibility="collapsed",\n            value=name_value,\n            key=name_key,\n            on_change=get_handler(item, name_key),\n        )\n    with col2:\n        st.write("")\n    return col3\n\n\ndef render_activities(i: int, item: Activity, item_type: EntityType) -> DeltaGenerator:\n    col1, col2, col3, col4 = st.columns([5, 5, 1, 1])\n    with col1:\n        name_value = item.name\n        name_key = f"[{item_type}][{i}][name]"\n\n        def get_handler(act: Activity, key: str) -> WidgetCallback:\n            def h() -> None:\n                act.name = st.session_state[key]\n\n            return h\n\n        st.text_input(\n            name_key,\n            label_visibility="collapsed",\n            value=name_value,\n            key=name_key,\n            on_change=get_handler(item, name_key),\n        )\n\n    with col2:\n        selected_dimensions_key = f"[{item_type}][{i}][dimensions]"\n        selected_dimensions: List[Dimension] = item.dimensions\n\n        dim_map = {dim.uid: dim.name for dim in repository().dimensions}\n\n        options = [dim.uid for dim in repository().dimensions]\n\n        def format_dim(dim_uid: Id) -> str:\n            return dim_map[dim_uid]\n\n        selected_dim_ids = [dim.uid for dim in selected_dimensions]\n\n        def update_activity(dim_ids: List[Id]) -> None:\n            item_dim_ids = [dim.uid for dim in item.dimensions]\n            for dim_id in dim_ids:\n                if dim_id not in item_dim_ids:\n                    item.assign_dimension(dim_id)\n                    print("add")\n            for dim in [dim for dim in repository().dimensions]:\n                if dim.uid not in dim_ids:\n                    item.unassign_dimension(dim)\n                    print("remove", dim.uid)\n\n        st.multiselect(\n            selected_dimensions_key,\n            label_visibility="collapsed",\n            options=options,\n            default=selected_dim_ids,\n            key=selected_dimensions_key,\n            on_change=lambda: update_activity(st.session_state[selected_dimensions_key]),\n            format_func=format_dim,\n        )\n    with col3:\n        st.write("")\n    return col4\n\n\ndef render_metrics(i: int, item: Metric, item_type: EntityType) -> DeltaGenerator:\n    col1, col2, col3, col4 = st.columns([5, 5, 1, 1])\n    with col1:\n        name_value = item.name\n        name_key = f"[{item_type}][{i}][name]"\n\n        def get_handler(m: Metric, key: str) -> WidgetCallback:\n            def h() -> None:\n                m.name = st.session_state[key]\n\n            return h\n\n        st.text_input(\n            name_key,\n            label_visibility="collapsed",\n            value=name_value,\n            key=name_key,\n            on_change=get_handler(item, name_key),\n        )\n    with col2:\n        selected_activity_key = f"[{item_type}][{i}][activity]"\n\n        act_map = {str(act.uid): act.name for act in repository().activities}\n\n        options = list(act_map.keys())\n\n        def format_act(act_uid: Id) -> str:\n            return act_map[act_uid]\n\n        def update_metric(act_id: Id) -> None:\n            item.act_id = act_id\n\n        st.selectbox(\n            label=selected_activity_key,\n            label_visibility="collapsed",\n            options=options,\n            format_func=format_act,\n            index=options.index(item.act_id) if item.act_id in options else 0,\n            key=selected_activity_key,\n            on_change=lambda: update_metric(st.session_state[selected_activity_key]),\n        )\n\n    with col3:\n        st.write("")\n    return col4\n\n\nRenderer = Callable[[int, Entity, EntityType], DeltaGenerator]\n\n\ndef render_crud(item_type: EntityType, items: List[Entity], render: Renderer, on_create: WidgetCallback) -> None:\n    for i, item in enumerate(items):\n        last_col = render(i, item, item_type)\n\n        def delete_item(entity: Entity) -> WidgetCallback:\n            return lambda: entity.delete()\n\n        last_col.button(f"Delete", key=f"{item_type}{i}_delete_button", on_click=delete_item(item))\n\n    st.button(f"Add {item_type.capitalize()}", on_click=on_create)\n\n\nclass DomaEntitiesPage(Page):\n    @property\n    def page_description(self) -> str:\n        return "This page provides a brief introduction to the DOMA framework and the purpose of the app."\n\n    def run(self) -> None:\n        st.markdown("### Summary")\n        graphviz_entities()\n\n        st.markdown(\n            """\n            Dimensions are attributes that describe characteristics of an object. \n            They are used to segment and filter data to gain insights into specific aspects of your business.\n\n            Some examples of dimensions might include: User, Location, Product, Category\n            """\n        )\n        render_crud(\n            item_type="dimension",\n            items=repository().dimensions,\n            render=render_dimensions,\n            on_create=lambda: Dimension.create(name=""),\n        )\n\n        st.markdown(\n            """\n            Activities are actions that occur within your business.\n            They are used to measure performance and identify areas for improvement.\n            \n            Some examples of activities might include:\n            Sales, Website Visits, Customer, Service Calls\n            """\n        )\n\n        activities = repository().activities\n        render_crud(\n            item_type="activity",\n            items=activities,\n            render=render_activities,\n            on_create=lambda: Activity.create(name=""),\n        )\n\n        st.markdown(\n            """\n            Metrics are numerical values that represent a specific aspect of your business performance.\n            They are calculated from a combination of dimensions and activities.\n            \n            Some examples of metrics might include: Revenue, Average Order Value, Conversion Rate\n            """\n        )\n        render_crud(\n            item_type="metric",\n            items=repository().metrics,\n            render=render_metrics,\n            on_create=lambda: Metric.create(name="", act_id=activities[0].uid if len(activities) else None),\n        )\n')
    __stickytape_write_module('app_pages/metrics_creation.py', b'from collections import ChainMap\nfrom typing import Dict, List\n\nimport pandas as pd\nimport streamlit as st\nfrom streamlit.runtime.state import WidgetCallback\n\nimport range_analysis_app.db as db\nfrom app_pages.page import Page\nfrom data.helpers import repository\nfrom data.metric import AGG_METHODS, Metric, MetricColumns\nfrom range_analysis_app.components.collapse import collapse\nfrom utils import chunks\n\n\nclass MetricsCreationPage(Page):\n    @property\n    def page_description(self) -> str:\n        return "This page provides a form where users can define metrics as answers to business questions."\n\n    def run(self) -> None:\n        metrics = repository().metrics\n\n        for metric in metrics:\n            if metric != metrics[0]:\n                st.markdown("---")\n\n            form_metric_definition(metric)\n\n\ndef form_metric_definition(metric: Metric) -> None:\n    activity = metric.activity\n    errors = activity.validate_tables_and_mapping()\n    if errors:\n        st.warning("Missing mapping in **:blue[Step 1]** and **:blue[Step 2]**.")\n        return\n\n    columns: Dict[str, db.DataType] = {\n        **activity.db_table.columns,\n        **ChainMap(*[dim.db_table.columns for dim in activity.dimensions]),\n    }\n\n    def columns_of_types(data_types: List[db.DataType]) -> List[str]:\n        """Return the columns having one of the given types."""\n        return [col for col, data_type in columns.items() if data_type in data_types]\n\n    metric_columns = columns_of_types(["FIXED", "REAL", "INTEGER"]) or ["<no number column>"]\n    timestamp_columns = columns_of_types(db.DATETIME_TYPES) or ["<no timestamp column>"]\n    text_columns = columns_of_types(["TEXT"]) or ["<no text column>"]\n\n    if metric.columns is None:\n        metric.columns = MetricColumns(\n            dimensions=[],\n            metric_column=metric_columns[0],\n            timestamp=timestamp_columns[0],\n            category=retrieve_category_column(text_columns),\n        )\n\n    def set_columns_field_and_update_dimensions(field: str, state_key: str) -> WidgetCallback:\n        def set_column():\n            column = st.session_state[state_key]\n            metric.columns.remove_dimension_columns({column})\n            setattr(metric.columns, field, column)\n\n        return set_column\n\n    def set_label(dimension: str, key: str) -> WidgetCallback:\n        def update_labels() -> None:\n            if value := st.session_state[key].strip():\n                metric.columns.labels.update(**{dimension: value})\n            else:\n                metric.columns.labels.pop(dimension, None)\n\n        return update_labels\n\n    left, right = st.columns([6, 6])\n\n    with left:\n        st.markdown("##### Attributes")\n        cols = st.columns([6, 6])\n        with cols[0]:\n            st.selectbox(\n                "**Measure**",\n                metric_columns,\n                index=metric_columns.index(metric.columns.metric_column),\n                key=f"metric-column-{metric.uid}",\n                on_change=set_columns_field_and_update_dimensions("metric_column", f"metric-column-{metric.uid}"),\n                help="Column containing a quantitative value to aggregate",\n            )\n            st.selectbox(\n                "**Timestamp**",\n                timestamp_columns,\n                index=timestamp_columns.index(metric.columns.timestamp),\n                key=f"timestamp-{metric.uid}",\n                on_change=set_columns_field_and_update_dimensions("timestamp", f"timestamp-{metric.uid}"),\n                help="Column containing the date of the event",\n            )\n            st.selectbox(\n                "**Product Category**",\n                text_columns,\n                index=text_columns.index(metric.columns.category),\n                key=f"category-{metric.uid}",\n                on_change=set_columns_field_and_update_dimensions("category", f"category-{metric.uid}"),\n                help="Column containing the category of the product",\n            )\n\n        with cols[1]:\n            st.text_input(\n                "**Label**",\n                value=metric.columns.labels.get(metric.columns.metric_column, ""),\n                placeholder="Type here...",\n                key=f"label-metric-{metric.uid}",\n                on_change=set_label(metric.columns.metric_column, f"label-metric-{metric.uid}"),\n            )\n            st.text_input(\n                "Label timestamp",\n                value=metric.columns.labels.get(metric.columns.timestamp, ""),\n                placeholder="Type here...",\n                key=f"label-timestamp-{metric.uid}",\n                on_change=set_label(metric.columns.timestamp, f"label-timestamp-{metric.uid}"),\n                label_visibility="hidden",\n            )\n            st.text_input(\n                "Label category",\n                value=metric.columns.labels.get(metric.columns.category, ""),\n                placeholder="Type here...",\n                key=f"label-category-{metric.uid}",\n                on_change=set_label(metric.columns.category, f"label-category-{metric.uid}"),\n                label_visibility="hidden",\n            )\n\n    with right:\n        st.markdown("##### Additional filters")\n\n        c = metric.columns\n        remaining_columns = [\n            col for col in columns if col not in [c.timestamp, c.metric_column, c.category] + c.dimensions\n        ]\n\n        for index, dim in enumerate(metric.columns.dimensions):\n            left, right, remove = st.columns([5, 5, 2])\n\n            def update_filter(dimension: str, state_key: str):\n                def update():\n                    metric.columns.dimensions[metric.columns.dimensions.index(dimension)] = st.session_state[state_key]\n\n                return update\n\n            left.selectbox(\n                "**Filter**",\n                [dim] + remaining_columns,\n                label_visibility="visible" if index == 0 else "collapsed",\n                key=f"dimension-{dim}",\n                on_change=update_filter(dim, f"dimension-{dim}"),\n            )\n            right.text_input(\n                "**Label**",\n                value=metric.columns.labels.get(dim, ""),\n                placeholder="Type here...",\n                key=f"label-{dim}-{metric.uid}",\n                on_change=set_label(dim, f"label-{dim}-{metric.uid}"),\n                label_visibility="visible" if index == 0 else "collapsed",\n            )\n\n            def remove_dim(dimension: str):\n                return lambda: metric.columns.dimensions.remove(dimension)\n\n            if index == 0:\n                remove.markdown("##")\n            remove.button("\xe2\x9c\x95", key=f"remove-{dim}", on_click=remove_dim(dim))\n\n        if remaining_columns:\n            left, _, _ = st.columns([5, 5, 2])\n\n            def add_filter():\n                metric.columns.dimensions.append(remaining_columns[0])\n\n            if not metric.columns.dimensions:\n                left.markdown("##")\n\n            left.button("\\+ Add filter", use_container_width=True, on_click=add_filter)\n\n    st.markdown("")\n    st.markdown("##### Preview (first 10)")\n    st.dataframe(metric.preview_dataframe(), use_container_width=True)\n\n\ndef retrieve_category_column(columns: List[str]) -> str:\n    """Retrieve the first column with the name looking like a category."""\n    CATEGORY_WORDS = ["CATEGORY", "KIND", "TYPE", "CAT"]\n\n    for word in CATEGORY_WORDS:\n        for col in columns:\n            if word in col.upper():\n                return col\n\n    return columns[0]\n')
    __stickytape_write_module('range_analysis_app/components/collapse.py', b'from typing import Optional\n\nimport streamlit as st\n\n\ndef collapse(label: str = "", open_by_default: str = False, key: Optional[str] = None) -> bool:\n    if not key:\n        key = f"collapse-{label}"\n\n    is_open = st.session_state.get(key, open_by_default)\n\n    def switch() -> None:\n        st.session_state[key] = not is_open\n\n    caret = "\xe2\xac\x86\xef\xb8\x8f" if is_open else "\xe2\xac\x87\xef\xb8\x8f"\n    st.button(f"{caret} {label}", on_click=switch, key=f"btn-{key}")\n\n    return is_open\n')
    __stickytape_write_module('app_pages/summary_settings_page.py', b'import streamlit as st\n\nfrom app_pages.page import Page\nfrom data.helpers import render_validation_component, repository, validate_state\n\n\nclass SummarySettingsPage(Page):\n    @property\n    def page_description(self) -> str:\n        return "Summary of settings"\n\n    def run(self) -> None:\n        _repo = repository()\n\n        _repo_dimensions = validate_state(_repo.dimensions, "dimension", validate_each=False)\n        _repo_activities = validate_state(_repo.activities, "activity", validate_each=False)\n        _repo_metrics = validate_state(_repo.metrics, "metric", validate_each=False)\n        _repo_each_dimensions = validate_state(_repo.dimensions, "dimension", validate_each=True)\n        _repo_each_activities = validate_state(_repo.activities, "activity", validate_each=True)\n        _repo_dim_act_mappings = validate_state(_repo.dim_act_mappings, "mapping column", permit_empty=True)\n        _repo_each_metrics = validate_state(_repo.metrics, "metric", validate_each=True)\n\n        col_entities, col_raw_data, col_mapping, col_metrics = st.columns(4)\n\n        with col_entities:\n            st.subheader("1. Entities")\n\n            render_validation_component(*_repo_dimensions)\n            render_validation_component(*_repo_activities)\n            render_validation_component(*_repo_metrics)\n\n        with col_raw_data:\n            st.subheader("2. RAW ERP Data")\n\n            render_validation_component(*_repo_each_dimensions)\n            render_validation_component(*_repo_each_activities)\n\n        with col_mapping:\n            st.subheader("3. Mapping")\n\n            render_validation_component(*_repo_dim_act_mappings)\n\n        with col_metrics:\n            st.subheader("4. Metrics")\n\n            render_validation_component(*_repo_each_metrics)\n')
    __stickytape_write_module('app_pages/settings_page.py', b'import streamlit as st\n\nfrom app_pages.data_loading import DataLoadingPage\nfrom app_pages.mapping import MappingPage\nfrom app_pages.metrics_creation import MetricsCreationPage\nfrom app_pages.page import Page\nfrom data.helpers import repository, save_repo_button\n\n\nclass SettingsPage(Page):\n    @property\n    def page_description(self) -> str:\n        return "Settings"\n\n    def run(self) -> None:\n        MODES = ["Demo Mode", "Custom Mode"]\n\n        def update_repo():\n            st.session_state["selected_repository"] = st.session_state["second-repo"]\n\n        st.radio(\n            "**Data Source**",\n            MODES,\n            index=MODES.index(st.session_state["selected_repository"]),\n            horizontal=True,\n            key="second-repo",\n            on_change=update_repo,\n        )\n\n        if last_updated_at := st.session_state.get("last_updated_at"):\n            st.markdown(f"Last updated on {last_updated_at.strftime(\'%Y-%m-%d %H:%M\')}")\n\n        config_section("Step 1 - Select Data Source and Map Dimensions")\n        DataLoadingPage().run()\n        st.markdown("---")\n\n        config_section("Step 2 - Specify Relationships Between Tables")\n        MappingPage().run()\n        st.markdown("---")\n\n        config_section("Step 3 - Select Attributes")\n        MetricsCreationPage().run()\n\n        # FIXME: Temporary fix for the flaky st.tabs and st.expander\n        # with st.expander("**Step 1 - Select Data Source and Map Dimensions**"):\n        #     DataLoadingPage().run()\n\n        # with st.expander("**Step 2 - Specify Relationships Between Tables**"):\n        #     MappingPage().run()\n\n        # with st.expander("**Step 3 - Select Attributes**"):\n        #     MetricsCreationPage().run()\n\n        if st.session_state["selected_repository"] == "Custom Mode":\n            save_config_button(key="save-config")\n\n\ndef save_config_button(key: str):\n    cols = st.columns([10, 2])\n    with cols[1]:\n        if save_repo_button(\n            "Save configuration",\n            key=key,\n            exclude={"widgets"},\n            before_save=apply_config_to_dashboard,\n        ):\n            st.experimental_rerun()\n\n\ndef config_section(title: str):\n    cols = st.columns([10, 2])\n    cols[0].markdown(f"### :blue[{title}]")\n\n\ndef apply_config_to_dashboard():\n    repo = repository()\n    updated_metric = repo.metrics[0]\n    for widget in repo.widgets:\n        widget.metric = updated_metric.copy()\n')
    __stickytape_write_module('app_pages/support_page.py', b'import streamlit as st\n\nfrom app_pages.page import Page\n\n\nclass SupportPage(Page):\n    @property\n    def page_description(self) -> str:\n        return "Support"\n\n    def run(self) -> None:\n        st.markdown(\n            """\n            - Explore the **Learn** section for best practices on how to use the Maxa app.\n            - Need assistance or have questions? Our dedicated support team is here to help.\n                - Visit [support.maxa.ai](https://support.maxa.ai) and fill out the support form.\n                - We appreciate your patience as we work to assist you!\n            """\n        )\n')
    import json
    from pathlib import Path
    
    import numpy as np
    import streamlit as st
    
    # noinspection PyUnresolvedReferences
    import range_analysis_app.components.streamlit_nested_layout  # import for nested columns support
    from app_pages.about_page import AboutPage
    from app_pages.dashboard import DashboardPage
    from app_pages.help_page import HelpPage
    from app_pages.settings_page import SettingsPage
    from app_pages.support_page import SupportPage
    from data.helpers import load_and_select_repository, save_repo_button
    from data.repository import Repository
    from streamlit_in_snowflake import snowflake_ui_styles, st_image_base64
    
    np.random.seed(seed=42)
    st.set_page_config(layout="wide", initial_sidebar_state="expanded")
    
    snowflake_ui_styles()
    
    load_and_select_repository()
    
    st_image_base64("bar.png", use_column_width=True)
    
    title_col, save_button_col = st.columns([10, 2])
    with title_col:
        st_image_base64("banner.png", width=400)
    with save_button_col:
        if st.session_state["selected_repository"] == "Custom Mode" and st.session_state.repository.is_valid():
            save_repo_button("Save Dashboard", key="save-dashboard", include={"widgets"})
    
    # FIXME: Temporary fix for the flaky st.tabs
    if st.session_state["selected_repository"] == "Custom Mode" and not st.session_state.repository.is_valid():
        config, learn, support, about = st.tabs(["Configuration", "Learn", "Support", "About Maxa"])
        with learn:
            HelpPage().run()
        with support:
            SupportPage().run()
        with about:
            AboutPage().run()
        with config:
            SettingsPage().run()
    
    else:
        dashboard, config, learn, support, about = st.tabs(["Dashboard", "Configuration", "Learn", "Support", "About Maxa"])
        with learn:
            HelpPage().run()
        with support:
            SupportPage().run()
        with about:
            AboutPage().run()
        with config:
            SettingsPage().run()
        with dashboard:
            DashboardPage().run()
    